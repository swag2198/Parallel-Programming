{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dotproduct.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNY_u5jeyJ9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "49ed3333-83b1-4032-839a-a1dec1dba02a"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-2vx3mk2k\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-2vx3mk2k\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=0abaeb55270cc3c61a3735ee73cf40067c7da30469c2613312adfb08fe67e432\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9gzi_8ax/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7VKmy1KyOIC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8334641f-0f6b-48df-cf29-4f840192b885"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOtPfT_VyQ7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d51d7e6-a96e-4126-c510-39111ccd07c7"
      },
      "source": [
        "%%cuda --name dotproduct.cu\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "#include <cmath>\n",
        "#include <ctime>\n",
        "#include <iostream>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define BLOCK_DIM 4\n",
        "\n",
        "using namespace std;\n",
        "typedef unsigned int ui;\n",
        "\n",
        "void printGPUproperties(cudaDeviceProp &devProp)\n",
        "{\n",
        "    printf(\"+++ Name : %s\\n\", devProp.name);\n",
        "    printf(\"    Total global memory : %ld bytes\\n\", devProp.totalGlobalMem);\n",
        "    printf(\"    Total shared memory per block : %ld bytes\\n\", devProp.sharedMemPerBlock);\n",
        "    printf(\"    Total shared memory per SM : %ld bytes\\n\", devProp.sharedMemPerMultiprocessor);\n",
        "    printf(\"    Memory bus width : %d bits\\n\", devProp.memoryBusWidth);\n",
        "    printf(\"    Memory clock rate : %d kHz\\n\", devProp.memoryClockRate);\n",
        "    printf(\"    Warp size : %d\\n\", devProp.warpSize);\n",
        "}\n",
        "\n",
        "void print_array(float *A, ui n)\n",
        "{\n",
        "    cout<<\"+++ Printing float array of length = \"<<n<<endl;\n",
        "    cout<<\"    \";\n",
        "    for(ui i = 0; i < n; i++)\n",
        "        printf(\"%.2f \", A[i]);\n",
        "    cout<<endl;\n",
        "}\n",
        "\n",
        "float cpudot(float *A, float *B, int n)\n",
        "{\n",
        "    float res = 0.0;\n",
        "    for(ui i=0; i<n; i++)\n",
        "    {\n",
        "        //if(i == 368)\n",
        "          //  cout<<\"ff \"<<A[i]<<\" sq = \"<<A[i]*B[i]<<\"+ = \"<<int(res + A[i]*B[i])<<endl;\n",
        "        res = res + (A[i] * B[i]);\n",
        "        //cout<<\"After i = \"<<i+1<<\", res = \";\n",
        "        //printf(\"%.2f \\n\", res);\n",
        "    }\n",
        "\n",
        "    return res;\n",
        "}\n",
        "\n",
        "__global__ void dotproduct(float *d_A, float *d_B, float *d_C, int n)\n",
        "{\n",
        "    __shared__ float tile[BLOCK_DIM];\n",
        "\n",
        "    ui i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    tile[threadIdx.x] = (i < n) ? (d_A[i] * d_B[i]) : 0;\n",
        "    __syncthreads();\n",
        " \n",
        "    if(threadIdx.x == 0)\n",
        "    {\n",
        "        float psum = 0.0;\n",
        "        for(ui j=0; j<blockDim.x; j++)\n",
        "            psum += tile[j];\n",
        "    \n",
        "        d_C[blockIdx.x] = psum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void dotproduct1(float *d_A, float *d_B, float *d_C, int n)\n",
        "{\n",
        "    __shared__ float tile[BLOCK_DIM];\n",
        "    ui i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    ui tid = threadIdx.x;\n",
        " \n",
        "    tile[tid] = (i < n) ? (d_A[i] * d_B[i]) : 0;\n",
        "    __syncthreads();\n",
        " \n",
        "    for(ui s = blockDim.x/2; s > 32; s >>= 1)\n",
        "    {\n",
        "        if(tid < s)\n",
        "            tile[tid] += tile[tid + s];\n",
        "        __syncthreads();\n",
        "    }\n",
        " \n",
        "    if(tid < 32)\n",
        "    {\n",
        "        tile[tid] += tile[tid + 32];\n",
        "        __syncthreads();\n",
        "        tile[tid] += tile[tid + 16];\n",
        "        __syncthreads();\n",
        "        tile[tid] += tile[tid + 8];\n",
        "        __syncthreads();\n",
        "        tile[tid] += tile[tid + 4];\n",
        "        __syncthreads();\n",
        "        tile[tid] += tile[tid + 2];\n",
        "        __syncthreads();\n",
        "        tile[tid] += tile[tid + 1];\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if(tid == 0)\n",
        "        d_C[blockIdx.x] = tile[0];\n",
        "}\n",
        "\n",
        "__global__ void reduce(float *d_B, float *d_C, int k)\n",
        "{\n",
        "    __shared__ float tile[BLOCK_DIM];\n",
        "    ui i = blockIdx.x * (blockDim.x * 2) + threadIdx.x;\n",
        "    ui tid = threadIdx.x;\n",
        "\n",
        "    tile[tid] = d_B[i] + d_B[i + BLOCK_DIM];\n",
        "    __syncthreads();\n",
        " \n",
        "    /*if(tid == 0 && blockIdx.x == 0)\n",
        "    {\n",
        "        printf(\"Tile content at block = %d\\n\", blockIdx.x);\n",
        "        for(int i=0; i<BLOCK_DIM; i++)\n",
        "            printf(\"%.2f \", tile[i]);\n",
        "        printf(\"\\n\");\n",
        "    }*/\n",
        " \n",
        "    for(ui s = blockDim.x/2; s > 32; s >>= 1)\n",
        "    {\n",
        "        if(tid < s)\n",
        "            tile[tid] += tile[tid + s];\n",
        "        __syncthreads();\n",
        "    }\n",
        " \n",
        "    if(tid < 32)\n",
        "    {\n",
        "        tile[tid] += tile[tid + 32];\n",
        "        __syncthreads();\n",
        "        tile[tid] += tile[tid + 16];\n",
        "        __syncthreads();\n",
        "        tile[tid] += tile[tid + 8];\n",
        "        __syncthreads();\n",
        "        tile[tid] += tile[tid + 4];\n",
        "        __syncthreads();\n",
        "        tile[tid] += tile[tid + 2];\n",
        "        __syncthreads();\n",
        "        tile[tid] += tile[tid + 1];\n",
        "        __syncthreads();\n",
        "    }\n",
        " \n",
        "    if(tid == 0)\n",
        "    {\n",
        "        //printf(\"Value = %.2f written at block no. = %d\\n\", tile[0], blockIdx.x);\n",
        "        d_C[blockIdx.x] = tile[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "void cpuReduce(float *a, ui n)\n",
        "{\n",
        "    float sum = 0.0;\n",
        "    for(ui i=0; i<n; i++)\n",
        "        sum += a[i];\n",
        " \n",
        "    a[0] = sum;\n",
        "}\n",
        "\n",
        "int main(int argc, char* argv[])\n",
        "{\n",
        "    cudaDeviceProp devprop;\n",
        "    cudaGetDeviceProperties(&devprop , 0);\n",
        "    printGPUproperties(devprop);\n",
        " \n",
        "    ui n;\n",
        "    //n = 1<<23;\n",
        "    n = atoi(argv[1]); //num_elements in each vector\n",
        "    const size_t size = n * sizeof(float);\n",
        "    cout<<\"+++ n = \"<<n<<endl;\n",
        "    cout<<\"    size = \"<<size<<\" bytes\"<<endl;\n",
        " \n",
        "    float *A, *B; //for cpu computations\n",
        "    float *h_A, *h_B, *h_C, *d_A, *d_B, *d_C; //for gpu computations\n",
        "    \n",
        "    ui n1 = (n + BLOCK_DIM - 1) / BLOCK_DIM;\n",
        "    const size_t size1 = n1 * sizeof(float);\n",
        "    cout<<\"    n1 = \"<<n1<<endl;\n",
        " \n",
        "    //Allocate Memory to cpu variables\n",
        "    h_A = (float *)malloc(size);\n",
        "    h_B = (float *)malloc(size);\n",
        "    h_C = (float *)malloc(size1);\n",
        "    A = (float *)malloc(size);\n",
        "    B = (float *)malloc(size);\n",
        " \n",
        "    //Allocate Memory to gpu variables\n",
        "    cudaMalloc((void **)&d_A, size);\n",
        "    cudaMalloc((void **)&d_B, size);\n",
        "    cudaMalloc((void **)&d_C, size1);\n",
        " \n",
        "    //Initialise CPU and GPU variables\n",
        "    for(ui i=0; i<n; i++)\n",
        "    {\n",
        "        //h_A[i] = (float(rand()) / (float(RAND_MAX)));\n",
        "        //h_A[i] = float(rand());\n",
        "        h_A[i] = 1.0 ;\n",
        "        //h_B[i] = (float(rand()) / (float(RAND_MAX)));\n",
        "        h_B[i] = 1.0 ;\n",
        "        //h_B[i] = h_A[i];\n",
        "\n",
        "        A[i] = h_A[i];\n",
        "        B[i] = h_B[i];\n",
        "    }\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        " \n",
        "    print_array(A, n);\n",
        "    //print_array(B, n);\n",
        "    //print_array(h_A, n);\n",
        "    //print_array(h_B, n);\n",
        " \n",
        "    //CPU transpose time\n",
        "    clock_t t1, t2;  \n",
        "    t1 = clock();\n",
        "    float result = cpudot(A, B, n);\n",
        "    t2 = clock();\n",
        "    printf(\"+++ n = %d, CPU Result = %.2f, CPU Dot Product time taken = %lf ms\\n\", n, result, ((double)(t2-t1)/(double)CLOCKS_PER_SEC) * 1000);\n",
        " \n",
        "    //GPU dotproduct\n",
        "    float ms;\n",
        "    dim3 block(BLOCK_DIM, 1, 1);\n",
        "    dim3 grid((n + block.x - 1)/block.x, 1, 1);\n",
        "    cout<<\"+++ Block Dim = (\"<<block.x<<\", \"<<block.y<<\")\"<<endl;\n",
        "    cout<<\"    Grid Dim = (\"<<grid.x<<\", \"<<grid.y<<\")\"<<endl;\n",
        " \n",
        "    cudaEvent_t c1, c2;\n",
        "    cudaEventCreate(&c1);\n",
        "    cudaEventCreate(&c2);\n",
        " \n",
        "    cudaEventRecord(c1);\n",
        "    dotproduct<<<grid, block>>>(d_A, d_B, d_C, n);\n",
        "    cudaEventRecord(c2);\n",
        " \n",
        "    cudaEventSynchronize(c2);\n",
        "    cudaEventElapsedTime(&ms, c1, c2);\n",
        "    cudaMemcpy(h_C, d_C, size1, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    printf(\"+++ n = %d, GPU Dot Product Reduce naive time taken = %lf ms\\n\", n, ms);\n",
        "    print_array(h_C, n1);\n",
        " \n",
        "    //Reallocate used placeholders\n",
        "    cudaFree(d_C);\n",
        "    free(h_C);\n",
        "    cudaMalloc((void **)&d_C, size1);\n",
        "    h_C = (float *)calloc(n1,  sizeof(float));\n",
        " \n",
        "    //GPU efficient dot reduce\n",
        "    cudaEventRecord(c1);\n",
        "    dotproduct1<<<grid, block>>>(d_A, d_B, d_C, n);\n",
        "    cudaEventRecord(c2);\n",
        " \n",
        "    cudaEventSynchronize(c2);\n",
        "    cudaEventElapsedTime(&ms, c1, c2);\n",
        "    cudaMemcpy(h_C, d_C, size1, cudaMemcpyDeviceToHost);\n",
        "    \n",
        "    printf(\"+++ n = %d, GPU Dot Product Reduce efficient time taken = %lf ms\\n\", n, ms);\n",
        "    print_array(h_C, n1);\n",
        " \n",
        "    ui curlen = n1;\n",
        "    while(curlen > BLOCK_DIM)\n",
        "    {\n",
        "        printf(\"In while for len = %d\\n\", curlen);\n",
        "        n1 = curlen;\n",
        "        grid.x = (curlen + BLOCK_DIM - 1) / BLOCK_DIM;\n",
        "        grid.x = grid.x / 2;\n",
        "     \n",
        "        cudaFree(d_B);\n",
        "        cudaMalloc((void **)&d_B, grid.x * sizeof(float));\n",
        "        free(h_C);\n",
        "        h_C = (float *)malloc(grid.x * sizeof(float));\n",
        "\n",
        "        cout<<\"+++ Block Dim = (\"<<block.x<<\", \"<<block.y<<\")\"<<endl;\n",
        "        cout<<\"    Grid Dim = (\"<<grid.x<<\", \"<<grid.y<<\")\"<<endl;\n",
        "        reduce<<<grid, block>>>(d_C, d_B, n1);\n",
        "        cudaMemcpy(h_C, d_B, grid.x * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "     \n",
        "        cudaFree(d_C);\n",
        "        cudaMalloc((void **)&d_C, grid.x * sizeof(float));\n",
        "        cudaMemcpy(d_C, h_C, grid.x * sizeof(float), cudaMemcpyHostToDevice);\n",
        "     \n",
        "        curlen = grid.x;\n",
        "        printf(\"curlen = %d\\n\", curlen);\n",
        "        print_array(h_C, curlen);   \n",
        "    }\n",
        "    cpuReduce(h_C, curlen);\n",
        "    printf(\"Final ans = \");\n",
        "    printf(\"%.2f\\n\", h_C[0]);\n",
        " \n",
        "    //cpuReduce(A, n);\n",
        "    //printf(\"Final ans = \");\n",
        "    //printf(\"%.2f\\n\", A[0]);\n",
        " \n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/dotproduct.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btm2S_COzzWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc /content/src/dotproduct.cu -o /content/src/dotproduct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaqw8KUSEZr2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "a1b72b75-993a-42d9-d836-1053351403cf"
      },
      "source": [
        "!/content/src/dotproduct 256 # 33554432"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+++ Name : Tesla T4\n",
            "    Total global memory : 15812263936 bytes\n",
            "    Total shared memory per block : 49152 bytes\n",
            "    Total shared memory per SM : 65536 bytes\n",
            "    Memory bus width : 256 bits\n",
            "    Memory clock rate : 5001000 kHz\n",
            "    Warp size : 32\n",
            "+++ n = 256\n",
            "    size = 1024 bytes\n",
            "    n1 = 64\n",
            "+++ Printing float array of length = 256\n",
            "    1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "+++ n = 256, CPU Result = 256.00, CPU Dot Product time taken = 0.003000 ms\n",
            "+++ Block Dim = (4, 1)\n",
            "    Grid Dim = (64, 1)\n",
            "+++ n = 256, GPU Dot Product Reduce naive time taken = 0.019840 ms\n",
            "+++ Printing float array of length = 64\n",
            "    4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 \n",
            "+++ n = 256, GPU Dot Product Reduce efficient time taken = 0.014464 ms\n",
            "+++ Printing float array of length = 64\n",
            "    4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 \n",
            "In while for len = 64\n",
            "+++ Block Dim = (4, 1)\n",
            "    Grid Dim = (8, 1)\n",
            "curlen = 8\n",
            "+++ Printing float array of length = 8\n",
            "    32.00 32.00 32.00 32.00 32.00 32.00 32.00 32.00 \n",
            "In while for len = 8\n",
            "+++ Block Dim = (4, 1)\n",
            "    Grid Dim = (1, 1)\n",
            "curlen = 1\n",
            "+++ Printing float array of length = 1\n",
            "    256.00 \n",
            "Final ans = 256.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZeuSPTUy85Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf94687b-ec10-4116-f2d7-f6435f59f09b"
      },
      "source": [
        "!nvprof --events warps_launched,local_load --metrics all /content/src/dotproduct 8192"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==513== NVPROF is profiling process 513, command: /content/src/dotproduct 8192\n",
            "+++ Name : Tesla P4\n",
            "    Total global memory : 7981694976 bytes\n",
            "    Total shared memory per block : 49152 bytes\n",
            "    Total shared memory per SM : 98304 bytes\n",
            "    Memory bus width : 256 bits\n",
            "    Memory clock rate : 3003000 kHz\n",
            "    Warp size : 32\n",
            "+++ n = 8192\n",
            "    size = 32768 bytes\n",
            "    n1 = 8\n",
            "+++ Printing float array of length = 8192\n",
            "    1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "+++ Printing float array of length = 8192\n",
            "    1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "+++ Printing float array of length = 8192\n",
            "    1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "+++ Printing float array of length = 8192\n",
            "    1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
            "+++ n = 8192, CPU Result = 8192.00, CPU Dot Product time taken = 0.035000 ms\n",
            "+++ Block Dim = (1024, 1)\n",
            "    Grid Dim = (8, 1)\n",
            "==513== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.\n",
            "==513== Replaying kernel \"dotproduct(float*, float*, float*, int)\" (1 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (2 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (3 of 55)... \n",
            "\tl2_subp0_read_tex_sector_queries\n",
            "\tl2_subp1_read_tex_sector_queries\n",
            "\t6 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[4A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[4A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (4 of 55)... \n",
            "\twarps_launched\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (5 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tfb_subp0_read_sectors\n",
            "\tfb_subp1_read_sectors\n",
            "\tfb_subp0_write_sectors\n",
            "\tfb_subp1_write_sectors\n",
            "\tinst_executed\n",
            "\tbranch\n",
            "\tdivergent_branch\n",
            "\tthread_inst_executed\n",
            "\tactive_cycles\n",
            "\tactive_warps\n",
            "\tl2_subp0_read_sector_misses\n",
            "\tl2_subp1_read_sector_misses\n",
            "\tl2_subp0_write_sector_misses\n",
            "\tl2_subp1_write_sector_misses\n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[17A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[17A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (6 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tglobal_atom_cas\n",
            "\tatom_count\n",
            "\tl2_subp0_write_tex_sector_queries\n",
            "\tl2_subp1_write_tex_sector_queries\n",
            "\t6 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[7A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[7A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (7 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (8 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (9 of 55)... \n",
            "\t5 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (10 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (11 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (12 of 55)... \n",
            "\t8 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (13 of 55)... \n",
            "\t1 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (14 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (15 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (16 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tlocal_store\n",
            "\tactive_cycles\n",
            "\tl2_subp0_total_read_sector_queries\n",
            "\tl2_subp1_total_read_sector_queries\n",
            "\t5 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[7A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[7A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (17 of 55)... \n",
            "\tgred_count\n",
            "\t7 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[3A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[3A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (18 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (19 of 55)... \n",
            "\ttex0_cache_sector_queries\n",
            "\ttex1_cache_sector_queries\n",
            "\tl2_subp0_read_tex_sector_queries\n",
            "\tl2_subp1_read_tex_sector_queries\n",
            "\t3 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[6A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[6A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (20 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (21 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (22 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (23 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (24 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (25 of 55)... \n",
            "\t1 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (26 of 55)... \n",
            "\tactive_cycles\n",
            "\tl2_subp0_write_tex_hit_sectors\n",
            "\tl2_subp1_write_tex_hit_sectors\n",
            "\t8 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[5A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[5A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (27 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (28 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tinst_executed\n",
            "\tnot_predicated_off_thread_inst_executed\n",
            "\tinst_issued1\n",
            "\tinst_issued2\n",
            "\tactive_cycles\n",
            "\tshared_ld_transactions\n",
            "\t6 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[9A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[9A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (29 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (30 of 55)... \n",
            "\t8 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (31 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (32 of 55)... \n",
            "\tactive_cycles\n",
            "\tshared_load\n",
            "\t9 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[4A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[4A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (33 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (34 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tlocal_load\n",
            "\tshared_ld_transactions\n",
            "\tshared_st_transactions\n",
            "\tl2_subp0_write_sysmem_sector_queries\n",
            "\tl2_subp1_write_sysmem_sector_queries\n",
            "\t7 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[8A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[8A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (35 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (36 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (37 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (38 of 55)... \n",
            "\t1 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (39 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (40 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tinst_executed_shared_atom_cas\n",
            "\tshared_atom\n",
            "\tinst_issued1\n",
            "\tinst_issued2\n",
            "\tl2_subp0_read_tex_hit_sectors\n",
            "\tl2_subp1_read_tex_hit_sectors\n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[9A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[9A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (41 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (42 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (43 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (44 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tglobal_store\n",
            "\tl2_subp0_total_write_sector_queries\n",
            "\tl2_subp1_total_write_sector_queries\n",
            "\t5 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[6A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[6A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (45 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (46 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (47 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (48 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (49 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (50 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (51 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (52 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (53 of 55)... \n",
            "\tinst_issued1\n",
            "\tinst_issued2\n",
            "\tactive_cycles\n",
            "\tl2_subp0_read_tex_sector_queries\n",
            "\tl2_subp1_read_tex_sector_queries\n",
            "\t6 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[7A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[7A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (54 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (55 of 55)... \n",
            "\tshared_store\n",
            "\tglobal_load\n",
            "\tl2_subp0_write_tex_sector_queries\n",
            "\tl2_subp1_write_tex_sector_queries\n",
            "\t6 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[6A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[5A\u001b[KReplaying kernel \"dotproduct(float*, float*, float*, int)\" (done)\n",
            "+++ n = 8192, GPU Dot Product Reduce naive time taken = 1723.139282 ms\n",
            "+++ Printing float array of length = 8\n",
            "    1024.00 1024.00 1024.00 1024.00 1024.00 1024.00 1024.00 1024.00 \n",
            "==513== Replaying kernel \"dotproduct1(float*, float*, float*, int)\" (1 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (2 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (3 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tlocal_store\n",
            "\tactive_cycles\n",
            "\tl2_subp0_total_read_sector_queries\n",
            "\tl2_subp1_total_read_sector_queries\n",
            "\t5 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[7A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[7A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (4 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (5 of 55)... \n",
            "\t8 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (6 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (7 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tinst_executed_shared_atom_cas\n",
            "\tshared_atom\n",
            "\tinst_issued1\n",
            "\tinst_issued2\n",
            "\tl2_subp0_read_tex_hit_sectors\n",
            "\tl2_subp1_read_tex_hit_sectors\n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[9A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[9A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (8 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (9 of 55)... \n",
            "\tshared_store\n",
            "\tglobal_load\n",
            "\tl2_subp0_write_tex_sector_queries\n",
            "\tl2_subp1_write_tex_sector_queries\n",
            "\t6 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[6A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[6A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (10 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (11 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (12 of 55)... \n",
            "\t8 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (13 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (14 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tglobal_atom_cas\n",
            "\tatom_count\n",
            "\tl2_subp0_write_tex_sector_queries\n",
            "\tl2_subp1_write_tex_sector_queries\n",
            "\t6 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[7A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[7A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (15 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tlocal_load\n",
            "\tshared_ld_transactions\n",
            "\tshared_st_transactions\n",
            "\tl2_subp0_write_sysmem_sector_queries\n",
            "\tl2_subp1_write_sysmem_sector_queries\n",
            "\t7 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[8A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[8A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (16 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (17 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (18 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (19 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (20 of 55)... \n",
            "\tactive_cycles\n",
            "\tshared_load\n",
            "\t9 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[4A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[4A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (21 of 55)... \n",
            "\t1 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (22 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (23 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (24 of 55)... \n",
            "\t1 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (25 of 55)... \n",
            "\t1 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (26 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (27 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (28 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (29 of 55)... \n",
            "\twarps_launched\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (30 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (31 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (32 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (33 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (34 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (35 of 55)... \n",
            "\tinst_issued1\n",
            "\tinst_issued2\n",
            "\tactive_cycles\n",
            "\tl2_subp0_read_tex_sector_queries\n",
            "\tl2_subp1_read_tex_sector_queries\n",
            "\t6 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[7A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[7A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (36 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (37 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (38 of 55)... \n",
            "\tl2_subp0_read_tex_sector_queries\n",
            "\tl2_subp1_read_tex_sector_queries\n",
            "\t6 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[4A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[4A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (39 of 55)... \n",
            "\ttex0_cache_sector_queries\n",
            "\ttex1_cache_sector_queries\n",
            "\tl2_subp0_read_tex_sector_queries\n",
            "\tl2_subp1_read_tex_sector_queries\n",
            "\t3 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[6A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[6A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (40 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (41 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (42 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (43 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (44 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (45 of 55)... \n",
            "\tactive_cycles\n",
            "\tl2_subp0_write_tex_hit_sectors\n",
            "\tl2_subp1_write_tex_hit_sectors\n",
            "\t8 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[5A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[5A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (46 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (47 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tfb_subp0_read_sectors\n",
            "\tfb_subp1_read_sectors\n",
            "\tfb_subp0_write_sectors\n",
            "\tfb_subp1_write_sectors\n",
            "\tinst_executed\n",
            "\tbranch\n",
            "\tdivergent_branch\n",
            "\tthread_inst_executed\n",
            "\tactive_cycles\n",
            "\tactive_warps\n",
            "\tl2_subp0_read_sector_misses\n",
            "\tl2_subp1_read_sector_misses\n",
            "\tl2_subp0_write_sector_misses\n",
            "\tl2_subp1_write_sector_misses\n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[17A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[17A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (48 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (49 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tglobal_store\n",
            "\tl2_subp0_total_write_sector_queries\n",
            "\tl2_subp1_total_write_sector_queries\n",
            "\t5 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[6A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[6A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (50 of 55)... \n",
            "\telapsed_cycles_sm\n",
            "\tinst_executed\n",
            "\tnot_predicated_off_thread_inst_executed\n",
            "\tinst_issued1\n",
            "\tinst_issued2\n",
            "\tactive_cycles\n",
            "\tshared_ld_transactions\n",
            "\t6 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[9A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[K\n",
            "\u001b[9A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (51 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (52 of 55)... \n",
            "\t2 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (53 of 55)... \n",
            "\t4 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (54 of 55)... \n",
            "\t5 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[2A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (55 of 55)... \n",
            "\tgred_count\n",
            "\t7 internal events\n",
            "==513== \u001b[1A\n",
            "\u001b[K\u001b[3A\u001b[K\n",
            "\u001b[K\n",
            "\u001b[2A\u001b[KReplaying kernel \"dotproduct1(float*, float*, float*, int)\" (done)\n",
            "+++ n = 8192, GPU Dot Product Reduce efficient time taken = 1621.820923 ms\n",
            "+++ Printing float array of length = 8\n",
            "    1024.00 1024.00 1024.00 1024.00 1024.00 1024.00 1024.00 1024.00 \n",
            "==513== Profiling application: /content/src/dotproduct 8192\n",
            "==513== Profiling result:\n",
            "==513== Event result:\n",
            "Invocations                                Event Name         Min         Max         Avg       Total\n",
            "Device \"Tesla P4 (0)\"\n",
            "    Kernel: dotproduct1(float*, float*, float*, int)\n",
            "          1                            warps_launched         256         256         256         256\n",
            "          1                                local_load           0           0           0           0\n",
            "    Kernel: dotproduct(float*, float*, float*, int)\n",
            "          1                            warps_launched         256         256         256         256\n",
            "          1                                local_load           0           0           0           0\n",
            "\n",
            "==513== Metric result:\n",
            "Invocations                               Metric Name                                                    Metric Description         Min         Max         Avg\n",
            "Device \"Tesla P4 (0)\"\n",
            "    Kernel: dotproduct1(float*, float*, float*, int)\n",
            "          1                             inst_per_warp                                                 Instructions per warp   95.750000   95.750000   95.750000\n",
            "          1                         branch_efficiency                                                     Branch Efficiency     100.00%     100.00%     100.00%\n",
            "          1                 warp_execution_efficiency                                             Warp Execution Efficiency      99.75%      99.75%      99.75%\n",
            "          1         warp_nonpred_execution_efficiency                              Warp Non-Predicated Execution Efficiency      77.39%      77.39%      77.39%\n",
            "          1                      inst_replay_overhead                                           Instruction Replay Overhead    0.029496    0.029496    0.029496\n",
            "          1      shared_load_transactions_per_request                           Shared Memory Load Transactions Per Request    0.271375    0.271375    0.271375\n",
            "          1     shared_store_transactions_per_request                          Shared Memory Store Transactions Per Request    0.409639    0.409639    0.409639\n",
            "          1       local_load_transactions_per_request                            Local Memory Load Transactions Per Request    0.000000    0.000000    0.000000\n",
            "          1      local_store_transactions_per_request                           Local Memory Store Transactions Per Request    0.000000    0.000000    0.000000\n",
            "          1              gld_transactions_per_request                                  Global Load Transactions Per Request   16.003906   16.003906   16.003906\n",
            "          1              gst_transactions_per_request                                 Global Store Transactions Per Request    1.000000    1.000000    1.000000\n",
            "          1                 shared_store_transactions                                             Shared Store Transactions         544         544         544\n",
            "          1                  shared_load_transactions                                              Shared Load Transactions         584         584         584\n",
            "          1                   local_load_transactions                                               Local Load Transactions           0           0           0\n",
            "          1                  local_store_transactions                                              Local Store Transactions           0           0           0\n",
            "          1                          gld_transactions                                              Global Load Transactions        8194        8194        8194\n",
            "          1                          gst_transactions                                             Global Store Transactions           8           8           8\n",
            "          1                  sysmem_read_transactions                                       System Memory Read Transactions           0           0           0\n",
            "          1                 sysmem_write_transactions                                      System Memory Write Transactions           5           5           5\n",
            "          1                      l2_read_transactions                                                  L2 Read Transactions        2112        2112        2112\n",
            "          1                     l2_write_transactions                                                 L2 Write Transactions          21          21          21\n",
            "          1                           global_hit_rate                                     Global Hit Rate in unified l1/tex       0.00%       0.00%       0.00%\n",
            "          1                            local_hit_rate                                                        Local Hit Rate       0.00%       0.00%       0.00%\n",
            "          1                  gld_requested_throughput                                      Requested Global Load Throughput  9.8938GB/s  9.8938GB/s  9.8938GB/s\n",
            "          1                  gst_requested_throughput                                     Requested Global Store Throughput  4.9469MB/s  4.9469MB/s  4.9468MB/s\n",
            "          1                            gld_throughput                                                Global Load Throughput  9.8938GB/s  9.8938GB/s  9.8938GB/s\n",
            "          1                            gst_throughput                                               Global Store Throughput  39.575MB/s  39.575MB/s  39.575MB/s\n",
            "          1                     local_memory_overhead                                                 Local Memory Overhead       0.00%       0.00%       0.00%\n",
            "          1                        tex_cache_hit_rate                                                Unified Cache Hit Rate      49.90%      49.90%      49.90%\n",
            "          1                      l2_tex_read_hit_rate                                           L2 Hit Rate (Texture Reads)     100.00%     100.00%     100.00%\n",
            "          1                     l2_tex_write_hit_rate                                          L2 Hit Rate (Texture Writes)     100.00%     100.00%     100.00%\n",
            "          1                      tex_cache_throughput                                              Unified Cache Throughput  9.8938GB/s  9.8938GB/s  9.8938GB/s\n",
            "          1                    l2_tex_read_throughput                                         L2 Throughput (Texture Reads)  9.8938GB/s  9.8938GB/s  9.8938GB/s\n",
            "          1                   l2_tex_write_throughput                                        L2 Throughput (Texture Writes)  39.575MB/s  39.575MB/s  39.575MB/s\n",
            "          1                        l2_read_throughput                                                 L2 Throughput (Reads)  10.203GB/s  10.203GB/s  10.203GB/s\n",
            "          1                       l2_write_throughput                                                L2 Throughput (Writes)  103.89MB/s  103.89MB/s  103.89MB/s\n",
            "          1                    sysmem_read_throughput                                         System Memory Read Throughput  0.00000B/s  0.00000B/s  0.00000B/s\n",
            "          1                   sysmem_write_throughput                                        System Memory Write Throughput  24.735MB/s  24.735MB/s  24.734MB/s\n",
            "          1                     local_load_throughput                                          Local Memory Load Throughput  0.00000B/s  0.00000B/s  0.00000B/s\n",
            "          1                    local_store_throughput                                         Local Memory Store Throughput  0.00000B/s  0.00000B/s  0.00000B/s\n",
            "          1                    shared_load_throughput                                         Shared Memory Load Throughput  11.285GB/s  11.285GB/s  11.285GB/s\n",
            "          1                   shared_store_throughput                                        Shared Memory Store Throughput  10.512GB/s  10.512GB/s  10.512GB/s\n",
            "          1                            gld_efficiency                                         Global Memory Load Efficiency     100.00%     100.00%     100.00%\n",
            "          1                            gst_efficiency                                        Global Memory Store Efficiency      12.50%      12.50%      12.50%\n",
            "          1                    tex_cache_transactions                                            Unified Cache Transactions        2048        2048        2048\n",
            "          1                             flop_count_dp                           Floating Point Operations(Double Precision)           0           0           0\n",
            "          1                         flop_count_dp_add                       Floating Point Operations(Double Precision Add)           0           0           0\n",
            "          1                         flop_count_dp_fma                       Floating Point Operations(Double Precision FMA)           0           0           0\n",
            "          1                         flop_count_dp_mul                       Floating Point Operations(Double Precision Mul)           0           0           0\n",
            "          1                             flop_count_sp                           Floating Point Operations(Single Precision)       17408       17408       17408\n",
            "          1                         flop_count_sp_add                       Floating Point Operations(Single Precision Add)        9216        9216        9216\n",
            "          1                         flop_count_sp_fma                       Floating Point Operations(Single Precision FMA)           0           0           0\n",
            "          1                         flop_count_sp_mul                        Floating Point Operation(Single Precision Mul)        8192        8192        8192\n",
            "          1                     flop_count_sp_special                   Floating Point Operations(Single Precision Special)           0           0           0\n",
            "          1                             inst_executed                                                 Instructions Executed       24512       24512       24512\n",
            "          1                               inst_issued                                                   Instructions Issued       25235       25235       25235\n",
            "          1                        sysmem_utilization                                             System Memory Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1                          stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)       8.95%       8.95%       8.95%\n",
            "          1                     stall_exec_dependency                            Issue Stall Reasons (Execution Dependency)      17.74%      17.74%      17.74%\n",
            "          1                   stall_memory_dependency                                    Issue Stall Reasons (Data Request)      10.82%      10.82%      10.82%\n",
            "          1                             stall_texture                                         Issue Stall Reasons (Texture)       0.00%       0.00%       0.00%\n",
            "          1                                stall_sync                                 Issue Stall Reasons (Synchronization)      28.00%      28.00%      28.00%\n",
            "          1                               stall_other                                           Issue Stall Reasons (Other)      18.48%      18.48%      18.48%\n",
            "          1          stall_constant_memory_dependency                              Issue Stall Reasons (Immediate constant)      13.68%      13.68%      13.68%\n",
            "          1                           stall_pipe_busy                                       Issue Stall Reasons (Pipe Busy)       0.84%       0.84%       0.84%\n",
            "          1                         shared_efficiency                                              Shared Memory Efficiency      99.31%      99.31%      99.31%\n",
            "          1                                inst_fp_32                                               FP Instructions(Single)       17408       17408       17408\n",
            "          1                                inst_fp_64                                               FP Instructions(Double)           0           0           0\n",
            "          1                              inst_integer                                                  Integer Instructions      228376      228376      228376\n",
            "          1                          inst_bit_convert                                              Bit-Convert Instructions           0           0           0\n",
            "          1                              inst_control                                             Control-Flow Instructions       65536       65536       65536\n",
            "          1                        inst_compute_ld_st                                               Load/Store Instructions       94736       94736       94736\n",
            "          1                                 inst_misc                                                     Misc Instructions      200976      200976      200976\n",
            "          1           inst_inter_thread_communication                                             Inter-Thread Instructions           0           0           0\n",
            "          1                               issue_slots                                                           Issue Slots       22667       22667       22667\n",
            "          1                                 cf_issued                                      Issued Control-Flow Instructions        2832        2832        2832\n",
            "          1                               cf_executed                                    Executed Control-Flow Instructions        2832        2832        2832\n",
            "          1                               ldst_issued                                        Issued Load/Store Instructions        8704        8704        8704\n",
            "          1                             ldst_executed                                      Executed Load/Store Instructions        8496        8496        8496\n",
            "          1                       atomic_transactions                                                   Atomic Transactions           0           0           0\n",
            "          1           atomic_transactions_per_request                                       Atomic Transactions Per Request    0.000000    0.000000    0.000000\n",
            "          1                      l2_atomic_throughput                                       L2 Throughput (Atomic requests)  0.00000B/s  0.00000B/s  0.00000B/s\n",
            "          1                    l2_atomic_transactions                                     L2 Transactions (Atomic requests)           0           0           0\n",
            "          1                  l2_tex_read_transactions                                       L2 Transactions (Texture Reads)        2048        2048        2048\n",
            "          1                     stall_memory_throttle                                 Issue Stall Reasons (Memory Throttle)       0.01%       0.01%       0.01%\n",
            "          1                        stall_not_selected                                    Issue Stall Reasons (Not Selected)       1.46%       1.46%       1.46%\n",
            "          1                 l2_tex_write_transactions                                      L2 Transactions (Texture Writes)           8           8           8\n",
            "          1                             flop_count_hp                             Floating Point Operations(Half Precision)           0           0           0\n",
            "          1                         flop_count_hp_add                         Floating Point Operations(Half Precision Add)           0           0           0\n",
            "          1                         flop_count_hp_mul                          Floating Point Operation(Half Precision Mul)           0           0           0\n",
            "          1                         flop_count_hp_fma                         Floating Point Operations(Half Precision FMA)           0           0           0\n",
            "          1                                inst_fp_16                                                 HP Instructions(Half)           0           0           0\n",
            "          1                   sysmem_read_utilization                                        System Memory Read Utilization    Idle (0)    Idle (0)    Idle (0)\n",
            "          1                  sysmem_write_utilization                                       System Memory Write Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1               pcie_total_data_transmitted                                           PCIe Total Data Transmitted         512         512         512\n",
            "          1                  pcie_total_data_received                                              PCIe Total Data Received           0           0           0\n",
            "          1                inst_executed_global_loads                              Warp level instructions for global loads         512         512         512\n",
            "          1                 inst_executed_local_loads                               Warp level instructions for local loads           0           0           0\n",
            "          1                inst_executed_shared_loads                              Warp level instructions for shared loads        2152        2152        2152\n",
            "          1               inst_executed_surface_loads                             Warp level instructions for surface loads           0           0           0\n",
            "          1               inst_executed_global_stores                             Warp level instructions for global stores           8           8           8\n",
            "          1                inst_executed_local_stores                              Warp level instructions for local stores           0           0           0\n",
            "          1               inst_executed_shared_stores                             Warp level instructions for shared stores        1328        1328        1328\n",
            "          1              inst_executed_surface_stores                            Warp level instructions for surface stores           0           0           0\n",
            "          1              inst_executed_global_atomics                  Warp level instructions for global atom and atom cas           0           0           0\n",
            "          1           inst_executed_global_reductions                         Warp level instructions for global reductions           0           0           0\n",
            "          1             inst_executed_surface_atomics                 Warp level instructions for surface atom and atom cas           0           0           0\n",
            "          1          inst_executed_surface_reductions                        Warp level instructions for surface reductions           0           0           0\n",
            "          1              inst_executed_shared_atomics                  Warp level shared instructions for atom and atom CAS           0           0           0\n",
            "          1                     inst_executed_tex_ops                                   Warp level instructions for texture           0           0           0\n",
            "          1                      l2_global_load_bytes       Bytes read from L2 for misses in Unified Cache for global loads       65536       65536       65536\n",
            "          1                       l2_local_load_bytes        Bytes read from L2 for misses in Unified Cache for local loads           0           0           0\n",
            "          1                     l2_surface_load_bytes      Bytes read from L2 for misses in Unified Cache for surface loads           0           0           0\n",
            "          1               l2_local_global_store_bytes   Bytes written to L2 from Unified Cache for local and global stores.         256         256         256\n",
            "          1                 l2_global_reduction_bytes          Bytes written to L2 from Unified cache for global reductions           0           0           0\n",
            "          1              l2_global_atomic_store_bytes             Bytes written to L2 from Unified cache for global atomics           0           0           0\n",
            "          1                    l2_surface_store_bytes            Bytes written to L2 from Unified Cache for surface stores.           0           0           0\n",
            "          1                l2_surface_reduction_bytes         Bytes written to L2 from Unified Cache for surface reductions           0           0           0\n",
            "          1             l2_surface_atomic_store_bytes    Bytes transferred between Unified Cache and L2 for surface atomics           0           0           0\n",
            "          1                      global_load_requests              Total number of global load requests from Multiprocessor        2048        2048        2048\n",
            "          1                       local_load_requests               Total number of local load requests from Multiprocessor           0           0           0\n",
            "          1                     surface_load_requests             Total number of surface load requests from Multiprocessor           0           0           0\n",
            "          1                     global_store_requests             Total number of global store requests from Multiprocessor           8           8           8\n",
            "          1                      local_store_requests              Total number of local store requests from Multiprocessor           0           0           0\n",
            "          1                    surface_store_requests            Total number of surface store requests from Multiprocessor           0           0           0\n",
            "          1                    global_atomic_requests            Total number of global atomic requests from Multiprocessor           0           0           0\n",
            "          1                 global_reduction_requests         Total number of global reduction requests from Multiprocessor           0           0           0\n",
            "          1                   surface_atomic_requests           Total number of surface atomic requests from Multiprocessor           0           0           0\n",
            "          1                surface_reduction_requests        Total number of surface reduction requests from Multiprocessor           0           0           0\n",
            "          1                         sysmem_read_bytes                                              System Memory Read Bytes           0           0           0\n",
            "          1                        sysmem_write_bytes                                             System Memory Write Bytes         160         160         160\n",
            "          1                           l2_tex_hit_rate                                                     L2 Cache Hit Rate     100.00%     100.00%     100.00%\n",
            "          1                     texture_load_requests             Total number of texture Load requests from Multiprocessor           0           0           0\n",
            "          1                     unique_warps_launched                                              Number of warps launched         256         256         256\n",
            "          1                             sm_efficiency                                               Multiprocessor Activity      19.09%      19.09%      19.09%\n",
            "          1                        achieved_occupancy                                                    Achieved Occupancy    0.348059    0.348059    0.348059\n",
            "          1                                       ipc                                                          Executed IPC    0.905738    0.905738    0.905738\n",
            "          1                                issued_ipc                                                            Issued IPC    0.850608    0.850608    0.850608\n",
            "          1                    issue_slot_utilization                                                Issue Slot Utilization      19.10%      19.10%      19.10%\n",
            "          1                  eligible_warps_per_cycle                                       Eligible Warps Per Active Cycle    1.046550    1.046550    1.046550\n",
            "          1                           tex_utilization                                             Unified Cache Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1                            l2_utilization                                                  L2 Cache Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1                        shared_utilization                                             Shared Memory Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1                       ldst_fu_utilization                                  Load/Store Function Unit Utilization     Low (2)     Low (2)     Low (2)\n",
            "          1                         cf_fu_utilization                                Control-Flow Function Unit Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1                    special_fu_utilization                                     Special Function Unit Utilization    Idle (0)    Idle (0)    Idle (0)\n",
            "          1                        tex_fu_utilization                                     Texture Function Unit Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1           single_precision_fu_utilization                            Single-Precision Function Unit Utilization     Low (2)     Low (2)     Low (2)\n",
            "          1           double_precision_fu_utilization                            Double-Precision Function Unit Utilization    Idle (0)    Idle (0)    Idle (0)\n",
            "          1                        flop_hp_efficiency                                            FLOP Efficiency(Peak Half)       0.00%       0.00%       0.00%\n",
            "          1                        flop_sp_efficiency                                          FLOP Efficiency(Peak Single)       0.05%       0.05%       0.05%\n",
            "          1                        flop_dp_efficiency                                          FLOP Efficiency(Peak Double)       0.00%       0.00%       0.00%\n",
            "          1                    dram_read_transactions                                       Device Memory Read Transactions           0           0           0\n",
            "          1                   dram_write_transactions                                      Device Memory Write Transactions          34          34          34\n",
            "          1                      dram_read_throughput                                         Device Memory Read Throughput  0.00000B/s  0.00000B/s  0.00000B/s\n",
            "          1                     dram_write_throughput                                        Device Memory Write Throughput  168.20MB/s  168.20MB/s  168.20MB/s\n",
            "          1                          dram_utilization                                             Device Memory Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1             half_precision_fu_utilization                              Half-Precision Function Unit Utilization    Idle (0)    Idle (0)    Idle (0)\n",
            "          1                          ecc_transactions                                                      ECC Transactions           7           7           7\n",
            "          1                            ecc_throughput                                                        ECC Throughput  34.628MB/s  34.628MB/s  34.628MB/s\n",
            "          1                           dram_read_bytes                                Total bytes read from DRAM to L2 cache           0           0           0\n",
            "          1                          dram_write_bytes                             Total bytes written from L2 cache to DRAM        1088        1088        1088\n",
            "    Kernel: dotproduct(float*, float*, float*, int)\n",
            "          1                             inst_per_warp                                                 Instructions per warp  102.937500  102.937500  102.937500\n",
            "          1                         branch_efficiency                                                     Branch Efficiency     100.00%     100.00%     100.00%\n",
            "          1                 warp_execution_efficiency                                             Warp Execution Efficiency      31.36%      31.36%      31.36%\n",
            "          1         warp_nonpred_execution_efficiency                              Warp Non-Predicated Execution Efficiency      30.38%      30.38%      30.38%\n",
            "          1                      inst_replay_overhead                                           Instruction Replay Overhead    0.025653    0.025653    0.025653\n",
            "          1      shared_load_transactions_per_request                           Shared Memory Load Transactions Per Request    1.000000    1.000000    1.000000\n",
            "          1     shared_store_transactions_per_request                          Shared Memory Store Transactions Per Request    1.000000    1.000000    1.000000\n",
            "          1       local_load_transactions_per_request                            Local Memory Load Transactions Per Request    0.000000    0.000000    0.000000\n",
            "          1      local_store_transactions_per_request                           Local Memory Store Transactions Per Request    0.000000    0.000000    0.000000\n",
            "          1              gld_transactions_per_request                                  Global Load Transactions Per Request   16.003906   16.003906   16.003906\n",
            "          1              gst_transactions_per_request                                 Global Store Transactions Per Request    1.000000    1.000000    1.000000\n",
            "          1                 shared_store_transactions                                             Shared Store Transactions         256         256         256\n",
            "          1                  shared_load_transactions                                              Shared Load Transactions        8192        8192        8192\n",
            "          1                   local_load_transactions                                               Local Load Transactions           0           0           0\n",
            "          1                  local_store_transactions                                              Local Store Transactions           0           0           0\n",
            "          1                          gld_transactions                                              Global Load Transactions        8194        8194        8194\n",
            "          1                          gst_transactions                                             Global Store Transactions           8           8           8\n",
            "          1                  sysmem_read_transactions                                       System Memory Read Transactions           0           0           0\n",
            "          1                 sysmem_write_transactions                                      System Memory Write Transactions           5           5           5\n",
            "          1                      l2_read_transactions                                                  L2 Read Transactions        2368        2368        2368\n",
            "          1                     l2_write_transactions                                                 L2 Write Transactions          21          21          21\n",
            "          1                           global_hit_rate                                     Global Hit Rate in unified l1/tex       0.00%       0.00%       0.00%\n",
            "          1                            local_hit_rate                                                        Local Hit Rate       0.00%       0.00%       0.00%\n",
            "          1                  gld_requested_throughput                                      Requested Global Load Throughput  4.6151GB/s  4.6151GB/s  4.6151GB/s\n",
            "          1                  gst_requested_throughput                                     Requested Global Store Throughput  2.3076MB/s  2.3076MB/s  2.3075MB/s\n",
            "          1                            gld_throughput                                                Global Load Throughput  4.6151GB/s  4.6151GB/s  4.6151GB/s\n",
            "          1                            gst_throughput                                               Global Store Throughput  18.461MB/s  18.461MB/s  18.460MB/s\n",
            "          1                     local_memory_overhead                                                 Local Memory Overhead       0.00%       0.00%       0.00%\n",
            "          1                        tex_cache_hit_rate                                                Unified Cache Hit Rate      49.90%      49.90%      49.90%\n",
            "          1                      l2_tex_read_hit_rate                                           L2 Hit Rate (Texture Reads)     100.00%     100.00%     100.00%\n",
            "          1                     l2_tex_write_hit_rate                                          L2 Hit Rate (Texture Writes)     100.00%     100.00%     100.00%\n",
            "          1                      tex_cache_throughput                                              Unified Cache Throughput  4.6151GB/s  4.6151GB/s  4.6151GB/s\n",
            "          1                    l2_tex_read_throughput                                         L2 Throughput (Texture Reads)  4.6151GB/s  4.6151GB/s  4.6151GB/s\n",
            "          1                   l2_tex_write_throughput                                        L2 Throughput (Texture Writes)  18.461MB/s  18.461MB/s  18.460MB/s\n",
            "          1                        l2_read_throughput                                                 L2 Throughput (Reads)  5.3362GB/s  5.3362GB/s  5.3362GB/s\n",
            "          1                       l2_write_throughput                                                L2 Throughput (Writes)  48.459MB/s  48.459MB/s  48.459MB/s\n",
            "          1                    sysmem_read_throughput                                         System Memory Read Throughput  0.00000B/s  0.00000B/s  0.00000B/s\n",
            "          1                   sysmem_write_throughput                                        System Memory Write Throughput  11.538MB/s  11.538MB/s  11.538MB/s\n",
            "          1                     local_load_throughput                                          Local Memory Load Throughput  0.00000B/s  0.00000B/s  0.00000B/s\n",
            "          1                    local_store_throughput                                         Local Memory Store Throughput  0.00000B/s  0.00000B/s  0.00000B/s\n",
            "          1                    shared_load_throughput                                         Shared Memory Load Throughput  73.842GB/s  73.842GB/s  73.842GB/s\n",
            "          1                   shared_store_throughput                                        Shared Memory Store Throughput  2.3076GB/s  2.3076GB/s  2.3076GB/s\n",
            "          1                            gld_efficiency                                         Global Memory Load Efficiency     100.00%     100.00%     100.00%\n",
            "          1                            gst_efficiency                                        Global Memory Store Efficiency      12.50%      12.50%      12.50%\n",
            "          1                    tex_cache_transactions                                            Unified Cache Transactions        2048        2048        2048\n",
            "          1                             flop_count_dp                           Floating Point Operations(Double Precision)           0           0           0\n",
            "          1                         flop_count_dp_add                       Floating Point Operations(Double Precision Add)           0           0           0\n",
            "          1                         flop_count_dp_fma                       Floating Point Operations(Double Precision FMA)           0           0           0\n",
            "          1                         flop_count_dp_mul                       Floating Point Operations(Double Precision Mul)           0           0           0\n",
            "          1                             flop_count_sp                           Floating Point Operations(Single Precision)       16384       16384       16384\n",
            "          1                         flop_count_sp_add                       Floating Point Operations(Single Precision Add)        8192        8192        8192\n",
            "          1                         flop_count_sp_fma                       Floating Point Operations(Single Precision FMA)           0           0           0\n",
            "          1                         flop_count_sp_mul                        Floating Point Operation(Single Precision Mul)        8192        8192        8192\n",
            "          1                     flop_count_sp_special                   Floating Point Operations(Single Precision Special)           0           0           0\n",
            "          1                             inst_executed                                                 Instructions Executed       26352       26352       26352\n",
            "          1                               inst_issued                                                   Instructions Issued       27028       27028       27028\n",
            "          1                        sysmem_utilization                                             System Memory Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1                          stall_inst_fetch                              Issue Stall Reasons (Instructions Fetch)       7.78%       7.78%       7.78%\n",
            "          1                     stall_exec_dependency                            Issue Stall Reasons (Execution Dependency)      27.66%      27.66%      27.66%\n",
            "          1                   stall_memory_dependency                                    Issue Stall Reasons (Data Request)      19.80%      19.80%      19.80%\n",
            "          1                             stall_texture                                         Issue Stall Reasons (Texture)       0.00%       0.00%       0.00%\n",
            "          1                                stall_sync                                 Issue Stall Reasons (Synchronization)       9.57%       9.57%       9.57%\n",
            "          1                               stall_other                                           Issue Stall Reasons (Other)       8.15%       8.15%       8.15%\n",
            "          1          stall_constant_memory_dependency                              Issue Stall Reasons (Immediate constant)      25.33%      25.33%      25.33%\n",
            "          1                           stall_pipe_busy                                       Issue Stall Reasons (Pipe Busy)       0.72%       0.72%       0.72%\n",
            "          1                         shared_efficiency                                              Shared Memory Efficiency       6.06%       6.06%       6.06%\n",
            "          1                                inst_fp_32                                               FP Instructions(Single)       16384       16384       16384\n",
            "          1                                inst_fp_64                                               FP Instructions(Double)           0           0           0\n",
            "          1                              inst_integer                                                  Integer Instructions       99952       99952       99952\n",
            "          1                          inst_bit_convert                                              Bit-Convert Instructions           0           0           0\n",
            "          1                              inst_control                                             Control-Flow Instructions       25104       25104       25104\n",
            "          1                        inst_compute_ld_st                                               Load/Store Instructions       40968       40968       40968\n",
            "          1                                 inst_misc                                                     Misc Instructions       73792       73792       73792\n",
            "          1           inst_inter_thread_communication                                             Inter-Thread Instructions           0           0           0\n",
            "          1                               issue_slots                                                           Issue Slots       18564       18564       18564\n",
            "          1                                 cf_issued                                      Issued Control-Flow Instructions        1592        1592        1592\n",
            "          1                               cf_executed                                    Executed Control-Flow Instructions        1592        1592        1592\n",
            "          1                               ldst_issued                                        Issued Load/Store Instructions       11528       11528       11528\n",
            "          1                             ldst_executed                                      Executed Load/Store Instructions       10248       10248       10248\n",
            "          1                       atomic_transactions                                                   Atomic Transactions           0           0           0\n",
            "          1           atomic_transactions_per_request                                       Atomic Transactions Per Request    0.000000    0.000000    0.000000\n",
            "          1                      l2_atomic_throughput                                       L2 Throughput (Atomic requests)  0.00000B/s  0.00000B/s  0.00000B/s\n",
            "          1                    l2_atomic_transactions                                     L2 Transactions (Atomic requests)           0           0           0\n",
            "          1                  l2_tex_read_transactions                                       L2 Transactions (Texture Reads)        2048        2048        2048\n",
            "          1                     stall_memory_throttle                                 Issue Stall Reasons (Memory Throttle)       0.05%       0.05%       0.05%\n",
            "          1                        stall_not_selected                                    Issue Stall Reasons (Not Selected)       0.95%       0.95%       0.95%\n",
            "          1                 l2_tex_write_transactions                                      L2 Transactions (Texture Writes)           8           8           8\n",
            "          1                             flop_count_hp                             Floating Point Operations(Half Precision)           0           0           0\n",
            "          1                         flop_count_hp_add                         Floating Point Operations(Half Precision Add)           0           0           0\n",
            "          1                         flop_count_hp_mul                          Floating Point Operation(Half Precision Mul)           0           0           0\n",
            "          1                         flop_count_hp_fma                         Floating Point Operations(Half Precision FMA)           0           0           0\n",
            "          1                                inst_fp_16                                                 HP Instructions(Half)           0           0           0\n",
            "          1                   sysmem_read_utilization                                        System Memory Read Utilization    Idle (0)    Idle (0)    Idle (0)\n",
            "          1                  sysmem_write_utilization                                       System Memory Write Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1               pcie_total_data_transmitted                                           PCIe Total Data Transmitted         512         512         512\n",
            "          1                  pcie_total_data_received                                              PCIe Total Data Received           0           0           0\n",
            "          1                inst_executed_global_loads                              Warp level instructions for global loads         512         512         512\n",
            "          1                 inst_executed_local_loads                               Warp level instructions for local loads           0           0           0\n",
            "          1                inst_executed_shared_loads                              Warp level instructions for shared loads        8192        8192        8192\n",
            "          1               inst_executed_surface_loads                             Warp level instructions for surface loads           0           0           0\n",
            "          1               inst_executed_global_stores                             Warp level instructions for global stores           8           8           8\n",
            "          1                inst_executed_local_stores                              Warp level instructions for local stores           0           0           0\n",
            "          1               inst_executed_shared_stores                             Warp level instructions for shared stores         256         256         256\n",
            "          1              inst_executed_surface_stores                            Warp level instructions for surface stores           0           0           0\n",
            "          1              inst_executed_global_atomics                  Warp level instructions for global atom and atom cas           0           0           0\n",
            "          1           inst_executed_global_reductions                         Warp level instructions for global reductions           0           0           0\n",
            "          1             inst_executed_surface_atomics                 Warp level instructions for surface atom and atom cas           0           0           0\n",
            "          1          inst_executed_surface_reductions                        Warp level instructions for surface reductions           0           0           0\n",
            "          1              inst_executed_shared_atomics                  Warp level shared instructions for atom and atom CAS           0           0           0\n",
            "          1                     inst_executed_tex_ops                                   Warp level instructions for texture           0           0           0\n",
            "          1                      l2_global_load_bytes       Bytes read from L2 for misses in Unified Cache for global loads       65536       65536       65536\n",
            "          1                       l2_local_load_bytes        Bytes read from L2 for misses in Unified Cache for local loads           0           0           0\n",
            "          1                     l2_surface_load_bytes      Bytes read from L2 for misses in Unified Cache for surface loads           0           0           0\n",
            "          1               l2_local_global_store_bytes   Bytes written to L2 from Unified Cache for local and global stores.         256         256         256\n",
            "          1                 l2_global_reduction_bytes          Bytes written to L2 from Unified cache for global reductions           0           0           0\n",
            "          1              l2_global_atomic_store_bytes             Bytes written to L2 from Unified cache for global atomics           0           0           0\n",
            "          1                    l2_surface_store_bytes            Bytes written to L2 from Unified Cache for surface stores.           0           0           0\n",
            "          1                l2_surface_reduction_bytes         Bytes written to L2 from Unified Cache for surface reductions           0           0           0\n",
            "          1             l2_surface_atomic_store_bytes    Bytes transferred between Unified Cache and L2 for surface atomics           0           0           0\n",
            "          1                      global_load_requests              Total number of global load requests from Multiprocessor        2048        2048        2048\n",
            "          1                       local_load_requests               Total number of local load requests from Multiprocessor           0           0           0\n",
            "          1                     surface_load_requests             Total number of surface load requests from Multiprocessor           0           0           0\n",
            "          1                     global_store_requests             Total number of global store requests from Multiprocessor           8           8           8\n",
            "          1                      local_store_requests              Total number of local store requests from Multiprocessor           0           0           0\n",
            "          1                    surface_store_requests            Total number of surface store requests from Multiprocessor           0           0           0\n",
            "          1                    global_atomic_requests            Total number of global atomic requests from Multiprocessor           0           0           0\n",
            "          1                 global_reduction_requests         Total number of global reduction requests from Multiprocessor           0           0           0\n",
            "          1                   surface_atomic_requests           Total number of surface atomic requests from Multiprocessor           0           0           0\n",
            "          1                surface_reduction_requests        Total number of surface reduction requests from Multiprocessor           0           0           0\n",
            "          1                         sysmem_read_bytes                                              System Memory Read Bytes           0           0           0\n",
            "          1                        sysmem_write_bytes                                             System Memory Write Bytes         160         160         160\n",
            "          1                           l2_tex_hit_rate                                                     L2 Cache Hit Rate     100.00%     100.00%     100.00%\n",
            "          1                     texture_load_requests             Total number of texture Load requests from Multiprocessor           0           0           0\n",
            "          1                     unique_warps_launched                                              Number of warps launched         256         256         256\n",
            "          1                             sm_efficiency                                               Multiprocessor Activity      28.86%      28.86%      28.86%\n",
            "          1                        achieved_occupancy                                                    Achieved Occupancy    0.069759    0.069759    0.069759\n",
            "          1                                       ipc                                                          Executed IPC    0.342585    0.342585    0.342585\n",
            "          1                                issued_ipc                                                            Issued IPC    0.335752    0.335752    0.335752\n",
            "          1                    issue_slot_utilization                                                Issue Slot Utilization       5.77%       5.77%       5.77%\n",
            "          1                  eligible_warps_per_cycle                                       Eligible Warps Per Active Cycle    0.269052    0.269052    0.269052\n",
            "          1                           tex_utilization                                             Unified Cache Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1                            l2_utilization                                                  L2 Cache Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1                        shared_utilization                                             Shared Memory Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1                       ldst_fu_utilization                                  Load/Store Function Unit Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1                         cf_fu_utilization                                Control-Flow Function Unit Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1                    special_fu_utilization                                     Special Function Unit Utilization    Idle (0)    Idle (0)    Idle (0)\n",
            "          1                        tex_fu_utilization                                     Texture Function Unit Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1           single_precision_fu_utilization                            Single-Precision Function Unit Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1           double_precision_fu_utilization                            Double-Precision Function Unit Utilization    Idle (0)    Idle (0)    Idle (0)\n",
            "          1                        flop_hp_efficiency                                            FLOP Efficiency(Peak Half)       0.00%       0.00%       0.00%\n",
            "          1                        flop_sp_efficiency                                          FLOP Efficiency(Peak Single)       0.02%       0.02%       0.02%\n",
            "          1                        flop_dp_efficiency                                          FLOP Efficiency(Peak Double)       0.00%       0.00%       0.00%\n",
            "          1                    dram_read_transactions                                       Device Memory Read Transactions           0           0           0\n",
            "          1                   dram_write_transactions                                      Device Memory Write Transactions          46          46          46\n",
            "          1                      dram_read_throughput                                         Device Memory Read Throughput  0.00000B/s  0.00000B/s  0.00000B/s\n",
            "          1                     dram_write_throughput                                        Device Memory Write Throughput  106.15MB/s  106.15MB/s  106.15MB/s\n",
            "          1                          dram_utilization                                             Device Memory Utilization     Low (1)     Low (1)     Low (1)\n",
            "          1             half_precision_fu_utilization                              Half-Precision Function Unit Utilization    Idle (0)    Idle (0)    Idle (0)\n",
            "          1                          ecc_transactions                                                      ECC Transactions           7           7           7\n",
            "          1                            ecc_throughput                                                        ECC Throughput  16.153MB/s  16.153MB/s  16.153MB/s\n",
            "          1                           dram_read_bytes                                Total bytes read from DRAM to L2 cache           0           0           0\n",
            "          1                          dram_write_bytes                             Total bytes written from L2 cache to DRAM        1472        1472        1472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P85bYvcfEaBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e5a5898-38cd-45d8-f2b1-f8587a68e391"
      },
      "source": [
        "!cuda-memcheck /content/src/dotproduct 256"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========= CUDA-MEMCHECK\n",
            "+++ Name : Tesla T4\n",
            "    Total global memory : 15812263936 bytes\n",
            "    Total shared memory per block : 49152 bytes\n",
            "    Total shared memory per SM : 65536 bytes\n",
            "    Memory bus width : 256 bits\n",
            "    Memory clock rate : 5001000 kHz\n",
            "    Warp size : 32\n",
            "+++ n = 256\n",
            "    size = 1024 bytes\n",
            "    n1 = 64\n",
            "+++ n = 256, CPU Result = 256.00, CPU Dot Product time taken = 0.003000 ms\n",
            "+++ Block Dim = (4, 1)\n",
            "    Grid Dim = (64, 1)\n",
            "+++ n = 256, GPU Dot Product Reduce naive time taken = 3.104224 ms\n",
            "+++ Printing float array of length = 64\n",
            "    4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 4.00 \n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (39,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (39,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (39,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (39,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (59,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (59,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (59,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (59,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (19,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (19,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (19,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (19,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (38,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (38,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (38,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (38,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (58,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (58,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (58,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (58,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (18,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (18,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (18,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (18,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (37,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (37,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (37,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (37,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (57,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (57,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (57,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (57,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (17,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (17,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (17,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (17,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (36,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (36,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (36,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (36,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (56,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (56,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (56,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (56,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (16,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (16,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (16,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (16,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (35,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (35,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (35,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (35,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (55,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (55,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (55,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (55,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (15,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (15,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (15,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (15,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (34,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (34,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (34,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (34,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (54,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (54,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (54,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (54,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (14,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (14,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (14,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (14,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (33,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (33,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (33,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (33,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (53,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (53,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (53,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (53,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (13,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (13,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (13,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (13,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (32,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (32,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (32,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (32,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (52,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (52,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (52,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (52,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (12,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (12,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (12,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (12,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (31,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (31,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (31,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (31,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (51,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (51,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (51,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (51,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (11,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (11,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (11,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (11,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (30,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (30,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (30,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (30,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (50,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (50,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (50,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (50,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (10,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (10,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (10,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (10,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (29,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (29,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (29,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (29,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (49,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (49,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (49,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (49,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (9,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (9,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (9,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (9,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (28,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (28,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (28,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (28,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (48,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (48,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (48,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (48,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (8,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (8,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (8,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (8,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (27,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (27,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (27,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (27,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (47,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (47,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (47,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (47,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (7,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (7,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (7,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (7,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (26,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (26,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (26,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (26,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (46,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (46,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (46,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (46,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (6,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (6,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (6,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (6,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (25,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (25,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (25,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (25,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (45,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (45,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (45,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (45,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (5,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (5,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (5,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (5,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (24,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (24,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (24,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (24,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (44,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (44,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (44,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (44,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (4,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (4,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (4,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (4,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (63,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (63,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (63,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (63,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (23,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (23,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (23,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (23,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (43,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (43,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (43,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (43,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (3,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (3,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (3,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (3,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (62,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (62,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (62,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (62,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (22,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (22,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (22,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (22,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (42,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (42,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (42,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (42,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (2,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (2,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (2,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (2,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (61,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (61,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (61,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (61,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (21,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (21,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (21,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (21,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (41,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (41,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (41,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (41,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (1,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (1,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (1,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (1,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (60,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (60,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (60,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (60,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (20,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (20,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (20,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (20,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (40,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (40,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (40,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (40,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (3,0,0) in block (0,0,0)\n",
            "=========     Address 0x0000008c is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (2,0,0) in block (0,0,0)\n",
            "=========     Address 0x00000088 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (1,0,0) in block (0,0,0)\n",
            "=========     Address 0x00000084 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Invalid __shared__ read of size 4\n",
            "=========     at 0x00000250 in dotproduct1(float*, float*, float*, int)\n",
            "=========     by thread (0,0,0) in block (0,0,0)\n",
            "=========     Address 0x00000080 is out of bounds\n",
            "=========     Device Frame:dotproduct1(float*, float*, float*, int) (dotproduct1(float*, float*, float*, int) : 0x250)\n",
            "=========     Saved host backtrace up to driver entry point at kernel launch time\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 (cuLaunchKernel + 0x2fe) [0x28187e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15009]\n",
            "=========     Host Frame:/content/src/dotproduct [0x15097]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b3e5]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7dae]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7e00]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7719]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaEventSynchronize. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x43b7e]\n",
            "=========     Host Frame:/content/src/dotproduct [0x773c]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaEventElapsedTime. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4383c]\n",
            "=========     Host Frame:/content/src/dotproduct [0x775c]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMemcpy. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x3564f]\n",
            "=========     Host Frame:/content/src/dotproduct [0x777e]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "+++ n = 256, GPU Dot Product Reduce efficient time taken = 3.104224 ms\n",
            "+++ Printing float array of length = 64\n",
            "    0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
            "In while for len = 64\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaFree. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x40f36]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7819]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMalloc. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x416b9]\n",
            "=========     Host Frame:/content/src/dotproduct [0x783b]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "+++ Block Dim = (4, 1)\n",
            "    Grid Dim = (16, 1)\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaLaunchKernel. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b425]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7f35]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7f82]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7994]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMemcpy. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x3564f]\n",
            "=========     Host Frame:/content/src/dotproduct [0x79bf]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaFree. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x40f36]\n",
            "=========     Host Frame:/content/src/dotproduct [0x79ce]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMalloc. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x416b9]\n",
            "=========     Host Frame:/content/src/dotproduct [0x79f0]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMemcpy. \n",
            "curlen = 16\n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "+++ Printing float array of length = 16\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x3564f]\n",
            "    1631715328.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
            "In while for len = 16\n",
            "=========     Host Frame:/content/src/dotproduct [0x7a1b]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaFree. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x40f36]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7819]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMalloc. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "+++ Block Dim = (4, 1)\n",
            "    Grid Dim = (4, 1)\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x416b9]\n",
            "=========     Host Frame:/content/src/dotproduct [0x783b]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaLaunchKernel. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b425]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7f35]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7f82]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7994]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMemcpy. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x3564f]\n",
            "=========     Host Frame:/content/src/dotproduct [0x79bf]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaFree. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x40f36]\n",
            "=========     Host Frame:/content/src/dotproduct [0x79ce]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMalloc. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x416b9]\n",
            "=========     Host Frame:/content/src/dotproduct [0x79f0]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMemcpy. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "curlen = 4\n",
            "+++ Printing float array of length = 4\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "    1703084032.00 0.00 538500032.00 0.00 \n",
            "In while for len = 4\n",
            "=========     Host Frame:/content/src/dotproduct [0x3564f]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7a1b]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaFree. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x40f36]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7819]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMalloc. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "+++ Block Dim = (4, 1)\n",
            "    Grid Dim = (1, 1)\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x416b9]\n",
            "=========     Host Frame:/content/src/dotproduct [0x783b]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaLaunchKernel. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x4b425]\n",
            "=========     Host Frame:/content/src/dotproduct [0x80f8]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7f35]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7f82]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7994]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMemcpy. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x3564f]\n",
            "=========     Host Frame:/content/src/dotproduct [0x79bf]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaFree. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x40f36]\n",
            "=========     Host Frame:/content/src/dotproduct [0x79ce]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMalloc. \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x416b9]\n",
            "=========     Host Frame:/content/src/dotproduct [0x79f0]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= Program hit cudaErrorLaunchFailure (error 719) due to \"unspecified launch failure\" on CUDA API call to cudaMemcpy. \n",
            "curlen = 1\n",
            "+++ Printing float array of length = 1\n",
            "    47527872.00 \n",
            "=========     Saved host backtrace up to driver entry point at error\n",
            "=========     Host Frame:/usr/lib64-nvidia/libcuda.so.1 [0x390513]\n",
            "=========     Host Frame:/content/src/dotproduct [0x3564f]\n",
            "=========     Host Frame:/content/src/dotproduct [0x7a1b]\n",
            "=========     Host Frame:/lib/x86_64-linux-gnu/libc.so.6 (__libc_start_main + 0xe7) [0x21b97]\n",
            "=========     Host Frame:/content/src/dotproduct [0x6d2a]\n",
            "=========\n",
            "========= ERROR SUMMARY: 280 errors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W7Hed4cE6cN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rgGqxghE6gE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f15CR5QEaEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMtbIFwkalSb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "aa7fed60-131c-4813-e81d-a047254b5a5c"
      },
      "source": [
        "!/content/src/dotproduct 2048 # 33554432"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+++ Name : Tesla P4\n",
            "    Total global memory : 7981694976 bytes\n",
            "    Total shared memory per block : 49152 bytes\n",
            "    Total shared memory per SM : 98304 bytes\n",
            "    Memory bus width : 256 bits\n",
            "    Memory clock rate : 3003000 kHz\n",
            "    Warp size : 32\n",
            "+++ n = 2048\n",
            "    size = 8192 bytes\n",
            "    n1 = 2\n",
            "+++ Printing float array of length = 2048\n",
            "    1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.00 11.00 12.00 13.00 14.00 15.00 16.00 17.00 18.00 19.00 20.00 21.00 22.00 23.00 24.00 25.00 26.00 27.00 28.00 29.00 30.00 31.00 32.00 33.00 34.00 35.00 36.00 37.00 38.00 39.00 40.00 41.00 42.00 43.00 44.00 45.00 46.00 47.00 48.00 49.00 50.00 51.00 52.00 53.00 54.00 55.00 56.00 57.00 58.00 59.00 60.00 61.00 62.00 63.00 64.00 65.00 66.00 67.00 68.00 69.00 70.00 71.00 72.00 73.00 74.00 75.00 76.00 77.00 78.00 79.00 80.00 81.00 82.00 83.00 84.00 85.00 86.00 87.00 88.00 89.00 90.00 91.00 92.00 93.00 94.00 95.00 96.00 97.00 98.00 99.00 100.00 101.00 102.00 103.00 104.00 105.00 106.00 107.00 108.00 109.00 110.00 111.00 112.00 113.00 114.00 115.00 116.00 117.00 118.00 119.00 120.00 121.00 122.00 123.00 124.00 125.00 126.00 127.00 128.00 129.00 130.00 131.00 132.00 133.00 134.00 135.00 136.00 137.00 138.00 139.00 140.00 141.00 142.00 143.00 144.00 145.00 146.00 147.00 148.00 149.00 150.00 151.00 152.00 153.00 154.00 155.00 156.00 157.00 158.00 159.00 160.00 161.00 162.00 163.00 164.00 165.00 166.00 167.00 168.00 169.00 170.00 171.00 172.00 173.00 174.00 175.00 176.00 177.00 178.00 179.00 180.00 181.00 182.00 183.00 184.00 185.00 186.00 187.00 188.00 189.00 190.00 191.00 192.00 193.00 194.00 195.00 196.00 197.00 198.00 199.00 200.00 201.00 202.00 203.00 204.00 205.00 206.00 207.00 208.00 209.00 210.00 211.00 212.00 213.00 214.00 215.00 216.00 217.00 218.00 219.00 220.00 221.00 222.00 223.00 224.00 225.00 226.00 227.00 228.00 229.00 230.00 231.00 232.00 233.00 234.00 235.00 236.00 237.00 238.00 239.00 240.00 241.00 242.00 243.00 244.00 245.00 246.00 247.00 248.00 249.00 250.00 251.00 252.00 253.00 254.00 255.00 256.00 257.00 258.00 259.00 260.00 261.00 262.00 263.00 264.00 265.00 266.00 267.00 268.00 269.00 270.00 271.00 272.00 273.00 274.00 275.00 276.00 277.00 278.00 279.00 280.00 281.00 282.00 283.00 284.00 285.00 286.00 287.00 288.00 289.00 290.00 291.00 292.00 293.00 294.00 295.00 296.00 297.00 298.00 299.00 300.00 301.00 302.00 303.00 304.00 305.00 306.00 307.00 308.00 309.00 310.00 311.00 312.00 313.00 314.00 315.00 316.00 317.00 318.00 319.00 320.00 321.00 322.00 323.00 324.00 325.00 326.00 327.00 328.00 329.00 330.00 331.00 332.00 333.00 334.00 335.00 336.00 337.00 338.00 339.00 340.00 341.00 342.00 343.00 344.00 345.00 346.00 347.00 348.00 349.00 350.00 351.00 352.00 353.00 354.00 355.00 356.00 357.00 358.00 359.00 360.00 361.00 362.00 363.00 364.00 365.00 366.00 367.00 368.00 369.00 370.00 371.00 372.00 373.00 374.00 375.00 376.00 377.00 378.00 379.00 380.00 381.00 382.00 383.00 384.00 385.00 386.00 387.00 388.00 389.00 390.00 391.00 392.00 393.00 394.00 395.00 396.00 397.00 398.00 399.00 400.00 401.00 402.00 403.00 404.00 405.00 406.00 407.00 408.00 409.00 410.00 411.00 412.00 413.00 414.00 415.00 416.00 417.00 418.00 419.00 420.00 421.00 422.00 423.00 424.00 425.00 426.00 427.00 428.00 429.00 430.00 431.00 432.00 433.00 434.00 435.00 436.00 437.00 438.00 439.00 440.00 441.00 442.00 443.00 444.00 445.00 446.00 447.00 448.00 449.00 450.00 451.00 452.00 453.00 454.00 455.00 456.00 457.00 458.00 459.00 460.00 461.00 462.00 463.00 464.00 465.00 466.00 467.00 468.00 469.00 470.00 471.00 472.00 473.00 474.00 475.00 476.00 477.00 478.00 479.00 480.00 481.00 482.00 483.00 484.00 485.00 486.00 487.00 488.00 489.00 490.00 491.00 492.00 493.00 494.00 495.00 496.00 497.00 498.00 499.00 500.00 501.00 502.00 503.00 504.00 505.00 506.00 507.00 508.00 509.00 510.00 511.00 512.00 513.00 514.00 515.00 516.00 517.00 518.00 519.00 520.00 521.00 522.00 523.00 524.00 525.00 526.00 527.00 528.00 529.00 530.00 531.00 532.00 533.00 534.00 535.00 536.00 537.00 538.00 539.00 540.00 541.00 542.00 543.00 544.00 545.00 546.00 547.00 548.00 549.00 550.00 551.00 552.00 553.00 554.00 555.00 556.00 557.00 558.00 559.00 560.00 561.00 562.00 563.00 564.00 565.00 566.00 567.00 568.00 569.00 570.00 571.00 572.00 573.00 574.00 575.00 576.00 577.00 578.00 579.00 580.00 581.00 582.00 583.00 584.00 585.00 586.00 587.00 588.00 589.00 590.00 591.00 592.00 593.00 594.00 595.00 596.00 597.00 598.00 599.00 600.00 601.00 602.00 603.00 604.00 605.00 606.00 607.00 608.00 609.00 610.00 611.00 612.00 613.00 614.00 615.00 616.00 617.00 618.00 619.00 620.00 621.00 622.00 623.00 624.00 625.00 626.00 627.00 628.00 629.00 630.00 631.00 632.00 633.00 634.00 635.00 636.00 637.00 638.00 639.00 640.00 641.00 642.00 643.00 644.00 645.00 646.00 647.00 648.00 649.00 650.00 651.00 652.00 653.00 654.00 655.00 656.00 657.00 658.00 659.00 660.00 661.00 662.00 663.00 664.00 665.00 666.00 667.00 668.00 669.00 670.00 671.00 672.00 673.00 674.00 675.00 676.00 677.00 678.00 679.00 680.00 681.00 682.00 683.00 684.00 685.00 686.00 687.00 688.00 689.00 690.00 691.00 692.00 693.00 694.00 695.00 696.00 697.00 698.00 699.00 700.00 701.00 702.00 703.00 704.00 705.00 706.00 707.00 708.00 709.00 710.00 711.00 712.00 713.00 714.00 715.00 716.00 717.00 718.00 719.00 720.00 721.00 722.00 723.00 724.00 725.00 726.00 727.00 728.00 729.00 730.00 731.00 732.00 733.00 734.00 735.00 736.00 737.00 738.00 739.00 740.00 741.00 742.00 743.00 744.00 745.00 746.00 747.00 748.00 749.00 750.00 751.00 752.00 753.00 754.00 755.00 756.00 757.00 758.00 759.00 760.00 761.00 762.00 763.00 764.00 765.00 766.00 767.00 768.00 769.00 770.00 771.00 772.00 773.00 774.00 775.00 776.00 777.00 778.00 779.00 780.00 781.00 782.00 783.00 784.00 785.00 786.00 787.00 788.00 789.00 790.00 791.00 792.00 793.00 794.00 795.00 796.00 797.00 798.00 799.00 800.00 801.00 802.00 803.00 804.00 805.00 806.00 807.00 808.00 809.00 810.00 811.00 812.00 813.00 814.00 815.00 816.00 817.00 818.00 819.00 820.00 821.00 822.00 823.00 824.00 825.00 826.00 827.00 828.00 829.00 830.00 831.00 832.00 833.00 834.00 835.00 836.00 837.00 838.00 839.00 840.00 841.00 842.00 843.00 844.00 845.00 846.00 847.00 848.00 849.00 850.00 851.00 852.00 853.00 854.00 855.00 856.00 857.00 858.00 859.00 860.00 861.00 862.00 863.00 864.00 865.00 866.00 867.00 868.00 869.00 870.00 871.00 872.00 873.00 874.00 875.00 876.00 877.00 878.00 879.00 880.00 881.00 882.00 883.00 884.00 885.00 886.00 887.00 888.00 889.00 890.00 891.00 892.00 893.00 894.00 895.00 896.00 897.00 898.00 899.00 900.00 901.00 902.00 903.00 904.00 905.00 906.00 907.00 908.00 909.00 910.00 911.00 912.00 913.00 914.00 915.00 916.00 917.00 918.00 919.00 920.00 921.00 922.00 923.00 924.00 925.00 926.00 927.00 928.00 929.00 930.00 931.00 932.00 933.00 934.00 935.00 936.00 937.00 938.00 939.00 940.00 941.00 942.00 943.00 944.00 945.00 946.00 947.00 948.00 949.00 950.00 951.00 952.00 953.00 954.00 955.00 956.00 957.00 958.00 959.00 960.00 961.00 962.00 963.00 964.00 965.00 966.00 967.00 968.00 969.00 970.00 971.00 972.00 973.00 974.00 975.00 976.00 977.00 978.00 979.00 980.00 981.00 982.00 983.00 984.00 985.00 986.00 987.00 988.00 989.00 990.00 991.00 992.00 993.00 994.00 995.00 996.00 997.00 998.00 999.00 1000.00 1001.00 1002.00 1003.00 1004.00 1005.00 1006.00 1007.00 1008.00 1009.00 1010.00 1011.00 1012.00 1013.00 1014.00 1015.00 1016.00 1017.00 1018.00 1019.00 1020.00 1021.00 1022.00 1023.00 1024.00 1025.00 1026.00 1027.00 1028.00 1029.00 1030.00 1031.00 1032.00 1033.00 1034.00 1035.00 1036.00 1037.00 1038.00 1039.00 1040.00 1041.00 1042.00 1043.00 1044.00 1045.00 1046.00 1047.00 1048.00 1049.00 1050.00 1051.00 1052.00 1053.00 1054.00 1055.00 1056.00 1057.00 1058.00 1059.00 1060.00 1061.00 1062.00 1063.00 1064.00 1065.00 1066.00 1067.00 1068.00 1069.00 1070.00 1071.00 1072.00 1073.00 1074.00 1075.00 1076.00 1077.00 1078.00 1079.00 1080.00 1081.00 1082.00 1083.00 1084.00 1085.00 1086.00 1087.00 1088.00 1089.00 1090.00 1091.00 1092.00 1093.00 1094.00 1095.00 1096.00 1097.00 1098.00 1099.00 1100.00 1101.00 1102.00 1103.00 1104.00 1105.00 1106.00 1107.00 1108.00 1109.00 1110.00 1111.00 1112.00 1113.00 1114.00 1115.00 1116.00 1117.00 1118.00 1119.00 1120.00 1121.00 1122.00 1123.00 1124.00 1125.00 1126.00 1127.00 1128.00 1129.00 1130.00 1131.00 1132.00 1133.00 1134.00 1135.00 1136.00 1137.00 1138.00 1139.00 1140.00 1141.00 1142.00 1143.00 1144.00 1145.00 1146.00 1147.00 1148.00 1149.00 1150.00 1151.00 1152.00 1153.00 1154.00 1155.00 1156.00 1157.00 1158.00 1159.00 1160.00 1161.00 1162.00 1163.00 1164.00 1165.00 1166.00 1167.00 1168.00 1169.00 1170.00 1171.00 1172.00 1173.00 1174.00 1175.00 1176.00 1177.00 1178.00 1179.00 1180.00 1181.00 1182.00 1183.00 1184.00 1185.00 1186.00 1187.00 1188.00 1189.00 1190.00 1191.00 1192.00 1193.00 1194.00 1195.00 1196.00 1197.00 1198.00 1199.00 1200.00 1201.00 1202.00 1203.00 1204.00 1205.00 1206.00 1207.00 1208.00 1209.00 1210.00 1211.00 1212.00 1213.00 1214.00 1215.00 1216.00 1217.00 1218.00 1219.00 1220.00 1221.00 1222.00 1223.00 1224.00 1225.00 1226.00 1227.00 1228.00 1229.00 1230.00 1231.00 1232.00 1233.00 1234.00 1235.00 1236.00 1237.00 1238.00 1239.00 1240.00 1241.00 1242.00 1243.00 1244.00 1245.00 1246.00 1247.00 1248.00 1249.00 1250.00 1251.00 1252.00 1253.00 1254.00 1255.00 1256.00 1257.00 1258.00 1259.00 1260.00 1261.00 1262.00 1263.00 1264.00 1265.00 1266.00 1267.00 1268.00 1269.00 1270.00 1271.00 1272.00 1273.00 1274.00 1275.00 1276.00 1277.00 1278.00 1279.00 1280.00 1281.00 1282.00 1283.00 1284.00 1285.00 1286.00 1287.00 1288.00 1289.00 1290.00 1291.00 1292.00 1293.00 1294.00 1295.00 1296.00 1297.00 1298.00 1299.00 1300.00 1301.00 1302.00 1303.00 1304.00 1305.00 1306.00 1307.00 1308.00 1309.00 1310.00 1311.00 1312.00 1313.00 1314.00 1315.00 1316.00 1317.00 1318.00 1319.00 1320.00 1321.00 1322.00 1323.00 1324.00 1325.00 1326.00 1327.00 1328.00 1329.00 1330.00 1331.00 1332.00 1333.00 1334.00 1335.00 1336.00 1337.00 1338.00 1339.00 1340.00 1341.00 1342.00 1343.00 1344.00 1345.00 1346.00 1347.00 1348.00 1349.00 1350.00 1351.00 1352.00 1353.00 1354.00 1355.00 1356.00 1357.00 1358.00 1359.00 1360.00 1361.00 1362.00 1363.00 1364.00 1365.00 1366.00 1367.00 1368.00 1369.00 1370.00 1371.00 1372.00 1373.00 1374.00 1375.00 1376.00 1377.00 1378.00 1379.00 1380.00 1381.00 1382.00 1383.00 1384.00 1385.00 1386.00 1387.00 1388.00 1389.00 1390.00 1391.00 1392.00 1393.00 1394.00 1395.00 1396.00 1397.00 1398.00 1399.00 1400.00 1401.00 1402.00 1403.00 1404.00 1405.00 1406.00 1407.00 1408.00 1409.00 1410.00 1411.00 1412.00 1413.00 1414.00 1415.00 1416.00 1417.00 1418.00 1419.00 1420.00 1421.00 1422.00 1423.00 1424.00 1425.00 1426.00 1427.00 1428.00 1429.00 1430.00 1431.00 1432.00 1433.00 1434.00 1435.00 1436.00 1437.00 1438.00 1439.00 1440.00 1441.00 1442.00 1443.00 1444.00 1445.00 1446.00 1447.00 1448.00 1449.00 1450.00 1451.00 1452.00 1453.00 1454.00 1455.00 1456.00 1457.00 1458.00 1459.00 1460.00 1461.00 1462.00 1463.00 1464.00 1465.00 1466.00 1467.00 1468.00 1469.00 1470.00 1471.00 1472.00 1473.00 1474.00 1475.00 1476.00 1477.00 1478.00 1479.00 1480.00 1481.00 1482.00 1483.00 1484.00 1485.00 1486.00 1487.00 1488.00 1489.00 1490.00 1491.00 1492.00 1493.00 1494.00 1495.00 1496.00 1497.00 1498.00 1499.00 1500.00 1501.00 1502.00 1503.00 1504.00 1505.00 1506.00 1507.00 1508.00 1509.00 1510.00 1511.00 1512.00 1513.00 1514.00 1515.00 1516.00 1517.00 1518.00 1519.00 1520.00 1521.00 1522.00 1523.00 1524.00 1525.00 1526.00 1527.00 1528.00 1529.00 1530.00 1531.00 1532.00 1533.00 1534.00 1535.00 1536.00 1537.00 1538.00 1539.00 1540.00 1541.00 1542.00 1543.00 1544.00 1545.00 1546.00 1547.00 1548.00 1549.00 1550.00 1551.00 1552.00 1553.00 1554.00 1555.00 1556.00 1557.00 1558.00 1559.00 1560.00 1561.00 1562.00 1563.00 1564.00 1565.00 1566.00 1567.00 1568.00 1569.00 1570.00 1571.00 1572.00 1573.00 1574.00 1575.00 1576.00 1577.00 1578.00 1579.00 1580.00 1581.00 1582.00 1583.00 1584.00 1585.00 1586.00 1587.00 1588.00 1589.00 1590.00 1591.00 1592.00 1593.00 1594.00 1595.00 1596.00 1597.00 1598.00 1599.00 1600.00 1601.00 1602.00 1603.00 1604.00 1605.00 1606.00 1607.00 1608.00 1609.00 1610.00 1611.00 1612.00 1613.00 1614.00 1615.00 1616.00 1617.00 1618.00 1619.00 1620.00 1621.00 1622.00 1623.00 1624.00 1625.00 1626.00 1627.00 1628.00 1629.00 1630.00 1631.00 1632.00 1633.00 1634.00 1635.00 1636.00 1637.00 1638.00 1639.00 1640.00 1641.00 1642.00 1643.00 1644.00 1645.00 1646.00 1647.00 1648.00 1649.00 1650.00 1651.00 1652.00 1653.00 1654.00 1655.00 1656.00 1657.00 1658.00 1659.00 1660.00 1661.00 1662.00 1663.00 1664.00 1665.00 1666.00 1667.00 1668.00 1669.00 1670.00 1671.00 1672.00 1673.00 1674.00 1675.00 1676.00 1677.00 1678.00 1679.00 1680.00 1681.00 1682.00 1683.00 1684.00 1685.00 1686.00 1687.00 1688.00 1689.00 1690.00 1691.00 1692.00 1693.00 1694.00 1695.00 1696.00 1697.00 1698.00 1699.00 1700.00 1701.00 1702.00 1703.00 1704.00 1705.00 1706.00 1707.00 1708.00 1709.00 1710.00 1711.00 1712.00 1713.00 1714.00 1715.00 1716.00 1717.00 1718.00 1719.00 1720.00 1721.00 1722.00 1723.00 1724.00 1725.00 1726.00 1727.00 1728.00 1729.00 1730.00 1731.00 1732.00 1733.00 1734.00 1735.00 1736.00 1737.00 1738.00 1739.00 1740.00 1741.00 1742.00 1743.00 1744.00 1745.00 1746.00 1747.00 1748.00 1749.00 1750.00 1751.00 1752.00 1753.00 1754.00 1755.00 1756.00 1757.00 1758.00 1759.00 1760.00 1761.00 1762.00 1763.00 1764.00 1765.00 1766.00 1767.00 1768.00 1769.00 1770.00 1771.00 1772.00 1773.00 1774.00 1775.00 1776.00 1777.00 1778.00 1779.00 1780.00 1781.00 1782.00 1783.00 1784.00 1785.00 1786.00 1787.00 1788.00 1789.00 1790.00 1791.00 1792.00 1793.00 1794.00 1795.00 1796.00 1797.00 1798.00 1799.00 1800.00 1801.00 1802.00 1803.00 1804.00 1805.00 1806.00 1807.00 1808.00 1809.00 1810.00 1811.00 1812.00 1813.00 1814.00 1815.00 1816.00 1817.00 1818.00 1819.00 1820.00 1821.00 1822.00 1823.00 1824.00 1825.00 1826.00 1827.00 1828.00 1829.00 1830.00 1831.00 1832.00 1833.00 1834.00 1835.00 1836.00 1837.00 1838.00 1839.00 1840.00 1841.00 1842.00 1843.00 1844.00 1845.00 1846.00 1847.00 1848.00 1849.00 1850.00 1851.00 1852.00 1853.00 1854.00 1855.00 1856.00 1857.00 1858.00 1859.00 1860.00 1861.00 1862.00 1863.00 1864.00 1865.00 1866.00 1867.00 1868.00 1869.00 1870.00 1871.00 1872.00 1873.00 1874.00 1875.00 1876.00 1877.00 1878.00 1879.00 1880.00 1881.00 1882.00 1883.00 1884.00 1885.00 1886.00 1887.00 1888.00 1889.00 1890.00 1891.00 1892.00 1893.00 1894.00 1895.00 1896.00 1897.00 1898.00 1899.00 1900.00 1901.00 1902.00 1903.00 1904.00 1905.00 1906.00 1907.00 1908.00 1909.00 1910.00 1911.00 1912.00 1913.00 1914.00 1915.00 1916.00 1917.00 1918.00 1919.00 1920.00 1921.00 1922.00 1923.00 1924.00 1925.00 1926.00 1927.00 1928.00 1929.00 1930.00 1931.00 1932.00 1933.00 1934.00 1935.00 1936.00 1937.00 1938.00 1939.00 1940.00 1941.00 1942.00 1943.00 1944.00 1945.00 1946.00 1947.00 1948.00 1949.00 1950.00 1951.00 1952.00 1953.00 1954.00 1955.00 1956.00 1957.00 1958.00 1959.00 1960.00 1961.00 1962.00 1963.00 1964.00 1965.00 1966.00 1967.00 1968.00 1969.00 1970.00 1971.00 1972.00 1973.00 1974.00 1975.00 1976.00 1977.00 1978.00 1979.00 1980.00 1981.00 1982.00 1983.00 1984.00 1985.00 1986.00 1987.00 1988.00 1989.00 1990.00 1991.00 1992.00 1993.00 1994.00 1995.00 1996.00 1997.00 1998.00 1999.00 2000.00 2001.00 2002.00 2003.00 2004.00 2005.00 2006.00 2007.00 2008.00 2009.00 2010.00 2011.00 2012.00 2013.00 2014.00 2015.00 2016.00 2017.00 2018.00 2019.00 2020.00 2021.00 2022.00 2023.00 2024.00 2025.00 2026.00 2027.00 2028.00 2029.00 2030.00 2031.00 2032.00 2033.00 2034.00 2035.00 2036.00 2037.00 2038.00 2039.00 2040.00 2041.00 2042.00 2043.00 2044.00 2045.00 2046.00 2047.00 2048.00 \n",
            "+++ Printing float array of length = 2048\n",
            "    1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.00 11.00 12.00 13.00 14.00 15.00 16.00 17.00 18.00 19.00 20.00 21.00 22.00 23.00 24.00 25.00 26.00 27.00 28.00 29.00 30.00 31.00 32.00 33.00 34.00 35.00 36.00 37.00 38.00 39.00 40.00 41.00 42.00 43.00 44.00 45.00 46.00 47.00 48.00 49.00 50.00 51.00 52.00 53.00 54.00 55.00 56.00 57.00 58.00 59.00 60.00 61.00 62.00 63.00 64.00 65.00 66.00 67.00 68.00 69.00 70.00 71.00 72.00 73.00 74.00 75.00 76.00 77.00 78.00 79.00 80.00 81.00 82.00 83.00 84.00 85.00 86.00 87.00 88.00 89.00 90.00 91.00 92.00 93.00 94.00 95.00 96.00 97.00 98.00 99.00 100.00 101.00 102.00 103.00 104.00 105.00 106.00 107.00 108.00 109.00 110.00 111.00 112.00 113.00 114.00 115.00 116.00 117.00 118.00 119.00 120.00 121.00 122.00 123.00 124.00 125.00 126.00 127.00 128.00 129.00 130.00 131.00 132.00 133.00 134.00 135.00 136.00 137.00 138.00 139.00 140.00 141.00 142.00 143.00 144.00 145.00 146.00 147.00 148.00 149.00 150.00 151.00 152.00 153.00 154.00 155.00 156.00 157.00 158.00 159.00 160.00 161.00 162.00 163.00 164.00 165.00 166.00 167.00 168.00 169.00 170.00 171.00 172.00 173.00 174.00 175.00 176.00 177.00 178.00 179.00 180.00 181.00 182.00 183.00 184.00 185.00 186.00 187.00 188.00 189.00 190.00 191.00 192.00 193.00 194.00 195.00 196.00 197.00 198.00 199.00 200.00 201.00 202.00 203.00 204.00 205.00 206.00 207.00 208.00 209.00 210.00 211.00 212.00 213.00 214.00 215.00 216.00 217.00 218.00 219.00 220.00 221.00 222.00 223.00 224.00 225.00 226.00 227.00 228.00 229.00 230.00 231.00 232.00 233.00 234.00 235.00 236.00 237.00 238.00 239.00 240.00 241.00 242.00 243.00 244.00 245.00 246.00 247.00 248.00 249.00 250.00 251.00 252.00 253.00 254.00 255.00 256.00 257.00 258.00 259.00 260.00 261.00 262.00 263.00 264.00 265.00 266.00 267.00 268.00 269.00 270.00 271.00 272.00 273.00 274.00 275.00 276.00 277.00 278.00 279.00 280.00 281.00 282.00 283.00 284.00 285.00 286.00 287.00 288.00 289.00 290.00 291.00 292.00 293.00 294.00 295.00 296.00 297.00 298.00 299.00 300.00 301.00 302.00 303.00 304.00 305.00 306.00 307.00 308.00 309.00 310.00 311.00 312.00 313.00 314.00 315.00 316.00 317.00 318.00 319.00 320.00 321.00 322.00 323.00 324.00 325.00 326.00 327.00 328.00 329.00 330.00 331.00 332.00 333.00 334.00 335.00 336.00 337.00 338.00 339.00 340.00 341.00 342.00 343.00 344.00 345.00 346.00 347.00 348.00 349.00 350.00 351.00 352.00 353.00 354.00 355.00 356.00 357.00 358.00 359.00 360.00 361.00 362.00 363.00 364.00 365.00 366.00 367.00 368.00 369.00 370.00 371.00 372.00 373.00 374.00 375.00 376.00 377.00 378.00 379.00 380.00 381.00 382.00 383.00 384.00 385.00 386.00 387.00 388.00 389.00 390.00 391.00 392.00 393.00 394.00 395.00 396.00 397.00 398.00 399.00 400.00 401.00 402.00 403.00 404.00 405.00 406.00 407.00 408.00 409.00 410.00 411.00 412.00 413.00 414.00 415.00 416.00 417.00 418.00 419.00 420.00 421.00 422.00 423.00 424.00 425.00 426.00 427.00 428.00 429.00 430.00 431.00 432.00 433.00 434.00 435.00 436.00 437.00 438.00 439.00 440.00 441.00 442.00 443.00 444.00 445.00 446.00 447.00 448.00 449.00 450.00 451.00 452.00 453.00 454.00 455.00 456.00 457.00 458.00 459.00 460.00 461.00 462.00 463.00 464.00 465.00 466.00 467.00 468.00 469.00 470.00 471.00 472.00 473.00 474.00 475.00 476.00 477.00 478.00 479.00 480.00 481.00 482.00 483.00 484.00 485.00 486.00 487.00 488.00 489.00 490.00 491.00 492.00 493.00 494.00 495.00 496.00 497.00 498.00 499.00 500.00 501.00 502.00 503.00 504.00 505.00 506.00 507.00 508.00 509.00 510.00 511.00 512.00 513.00 514.00 515.00 516.00 517.00 518.00 519.00 520.00 521.00 522.00 523.00 524.00 525.00 526.00 527.00 528.00 529.00 530.00 531.00 532.00 533.00 534.00 535.00 536.00 537.00 538.00 539.00 540.00 541.00 542.00 543.00 544.00 545.00 546.00 547.00 548.00 549.00 550.00 551.00 552.00 553.00 554.00 555.00 556.00 557.00 558.00 559.00 560.00 561.00 562.00 563.00 564.00 565.00 566.00 567.00 568.00 569.00 570.00 571.00 572.00 573.00 574.00 575.00 576.00 577.00 578.00 579.00 580.00 581.00 582.00 583.00 584.00 585.00 586.00 587.00 588.00 589.00 590.00 591.00 592.00 593.00 594.00 595.00 596.00 597.00 598.00 599.00 600.00 601.00 602.00 603.00 604.00 605.00 606.00 607.00 608.00 609.00 610.00 611.00 612.00 613.00 614.00 615.00 616.00 617.00 618.00 619.00 620.00 621.00 622.00 623.00 624.00 625.00 626.00 627.00 628.00 629.00 630.00 631.00 632.00 633.00 634.00 635.00 636.00 637.00 638.00 639.00 640.00 641.00 642.00 643.00 644.00 645.00 646.00 647.00 648.00 649.00 650.00 651.00 652.00 653.00 654.00 655.00 656.00 657.00 658.00 659.00 660.00 661.00 662.00 663.00 664.00 665.00 666.00 667.00 668.00 669.00 670.00 671.00 672.00 673.00 674.00 675.00 676.00 677.00 678.00 679.00 680.00 681.00 682.00 683.00 684.00 685.00 686.00 687.00 688.00 689.00 690.00 691.00 692.00 693.00 694.00 695.00 696.00 697.00 698.00 699.00 700.00 701.00 702.00 703.00 704.00 705.00 706.00 707.00 708.00 709.00 710.00 711.00 712.00 713.00 714.00 715.00 716.00 717.00 718.00 719.00 720.00 721.00 722.00 723.00 724.00 725.00 726.00 727.00 728.00 729.00 730.00 731.00 732.00 733.00 734.00 735.00 736.00 737.00 738.00 739.00 740.00 741.00 742.00 743.00 744.00 745.00 746.00 747.00 748.00 749.00 750.00 751.00 752.00 753.00 754.00 755.00 756.00 757.00 758.00 759.00 760.00 761.00 762.00 763.00 764.00 765.00 766.00 767.00 768.00 769.00 770.00 771.00 772.00 773.00 774.00 775.00 776.00 777.00 778.00 779.00 780.00 781.00 782.00 783.00 784.00 785.00 786.00 787.00 788.00 789.00 790.00 791.00 792.00 793.00 794.00 795.00 796.00 797.00 798.00 799.00 800.00 801.00 802.00 803.00 804.00 805.00 806.00 807.00 808.00 809.00 810.00 811.00 812.00 813.00 814.00 815.00 816.00 817.00 818.00 819.00 820.00 821.00 822.00 823.00 824.00 825.00 826.00 827.00 828.00 829.00 830.00 831.00 832.00 833.00 834.00 835.00 836.00 837.00 838.00 839.00 840.00 841.00 842.00 843.00 844.00 845.00 846.00 847.00 848.00 849.00 850.00 851.00 852.00 853.00 854.00 855.00 856.00 857.00 858.00 859.00 860.00 861.00 862.00 863.00 864.00 865.00 866.00 867.00 868.00 869.00 870.00 871.00 872.00 873.00 874.00 875.00 876.00 877.00 878.00 879.00 880.00 881.00 882.00 883.00 884.00 885.00 886.00 887.00 888.00 889.00 890.00 891.00 892.00 893.00 894.00 895.00 896.00 897.00 898.00 899.00 900.00 901.00 902.00 903.00 904.00 905.00 906.00 907.00 908.00 909.00 910.00 911.00 912.00 913.00 914.00 915.00 916.00 917.00 918.00 919.00 920.00 921.00 922.00 923.00 924.00 925.00 926.00 927.00 928.00 929.00 930.00 931.00 932.00 933.00 934.00 935.00 936.00 937.00 938.00 939.00 940.00 941.00 942.00 943.00 944.00 945.00 946.00 947.00 948.00 949.00 950.00 951.00 952.00 953.00 954.00 955.00 956.00 957.00 958.00 959.00 960.00 961.00 962.00 963.00 964.00 965.00 966.00 967.00 968.00 969.00 970.00 971.00 972.00 973.00 974.00 975.00 976.00 977.00 978.00 979.00 980.00 981.00 982.00 983.00 984.00 985.00 986.00 987.00 988.00 989.00 990.00 991.00 992.00 993.00 994.00 995.00 996.00 997.00 998.00 999.00 1000.00 1001.00 1002.00 1003.00 1004.00 1005.00 1006.00 1007.00 1008.00 1009.00 1010.00 1011.00 1012.00 1013.00 1014.00 1015.00 1016.00 1017.00 1018.00 1019.00 1020.00 1021.00 1022.00 1023.00 1024.00 1025.00 1026.00 1027.00 1028.00 1029.00 1030.00 1031.00 1032.00 1033.00 1034.00 1035.00 1036.00 1037.00 1038.00 1039.00 1040.00 1041.00 1042.00 1043.00 1044.00 1045.00 1046.00 1047.00 1048.00 1049.00 1050.00 1051.00 1052.00 1053.00 1054.00 1055.00 1056.00 1057.00 1058.00 1059.00 1060.00 1061.00 1062.00 1063.00 1064.00 1065.00 1066.00 1067.00 1068.00 1069.00 1070.00 1071.00 1072.00 1073.00 1074.00 1075.00 1076.00 1077.00 1078.00 1079.00 1080.00 1081.00 1082.00 1083.00 1084.00 1085.00 1086.00 1087.00 1088.00 1089.00 1090.00 1091.00 1092.00 1093.00 1094.00 1095.00 1096.00 1097.00 1098.00 1099.00 1100.00 1101.00 1102.00 1103.00 1104.00 1105.00 1106.00 1107.00 1108.00 1109.00 1110.00 1111.00 1112.00 1113.00 1114.00 1115.00 1116.00 1117.00 1118.00 1119.00 1120.00 1121.00 1122.00 1123.00 1124.00 1125.00 1126.00 1127.00 1128.00 1129.00 1130.00 1131.00 1132.00 1133.00 1134.00 1135.00 1136.00 1137.00 1138.00 1139.00 1140.00 1141.00 1142.00 1143.00 1144.00 1145.00 1146.00 1147.00 1148.00 1149.00 1150.00 1151.00 1152.00 1153.00 1154.00 1155.00 1156.00 1157.00 1158.00 1159.00 1160.00 1161.00 1162.00 1163.00 1164.00 1165.00 1166.00 1167.00 1168.00 1169.00 1170.00 1171.00 1172.00 1173.00 1174.00 1175.00 1176.00 1177.00 1178.00 1179.00 1180.00 1181.00 1182.00 1183.00 1184.00 1185.00 1186.00 1187.00 1188.00 1189.00 1190.00 1191.00 1192.00 1193.00 1194.00 1195.00 1196.00 1197.00 1198.00 1199.00 1200.00 1201.00 1202.00 1203.00 1204.00 1205.00 1206.00 1207.00 1208.00 1209.00 1210.00 1211.00 1212.00 1213.00 1214.00 1215.00 1216.00 1217.00 1218.00 1219.00 1220.00 1221.00 1222.00 1223.00 1224.00 1225.00 1226.00 1227.00 1228.00 1229.00 1230.00 1231.00 1232.00 1233.00 1234.00 1235.00 1236.00 1237.00 1238.00 1239.00 1240.00 1241.00 1242.00 1243.00 1244.00 1245.00 1246.00 1247.00 1248.00 1249.00 1250.00 1251.00 1252.00 1253.00 1254.00 1255.00 1256.00 1257.00 1258.00 1259.00 1260.00 1261.00 1262.00 1263.00 1264.00 1265.00 1266.00 1267.00 1268.00 1269.00 1270.00 1271.00 1272.00 1273.00 1274.00 1275.00 1276.00 1277.00 1278.00 1279.00 1280.00 1281.00 1282.00 1283.00 1284.00 1285.00 1286.00 1287.00 1288.00 1289.00 1290.00 1291.00 1292.00 1293.00 1294.00 1295.00 1296.00 1297.00 1298.00 1299.00 1300.00 1301.00 1302.00 1303.00 1304.00 1305.00 1306.00 1307.00 1308.00 1309.00 1310.00 1311.00 1312.00 1313.00 1314.00 1315.00 1316.00 1317.00 1318.00 1319.00 1320.00 1321.00 1322.00 1323.00 1324.00 1325.00 1326.00 1327.00 1328.00 1329.00 1330.00 1331.00 1332.00 1333.00 1334.00 1335.00 1336.00 1337.00 1338.00 1339.00 1340.00 1341.00 1342.00 1343.00 1344.00 1345.00 1346.00 1347.00 1348.00 1349.00 1350.00 1351.00 1352.00 1353.00 1354.00 1355.00 1356.00 1357.00 1358.00 1359.00 1360.00 1361.00 1362.00 1363.00 1364.00 1365.00 1366.00 1367.00 1368.00 1369.00 1370.00 1371.00 1372.00 1373.00 1374.00 1375.00 1376.00 1377.00 1378.00 1379.00 1380.00 1381.00 1382.00 1383.00 1384.00 1385.00 1386.00 1387.00 1388.00 1389.00 1390.00 1391.00 1392.00 1393.00 1394.00 1395.00 1396.00 1397.00 1398.00 1399.00 1400.00 1401.00 1402.00 1403.00 1404.00 1405.00 1406.00 1407.00 1408.00 1409.00 1410.00 1411.00 1412.00 1413.00 1414.00 1415.00 1416.00 1417.00 1418.00 1419.00 1420.00 1421.00 1422.00 1423.00 1424.00 1425.00 1426.00 1427.00 1428.00 1429.00 1430.00 1431.00 1432.00 1433.00 1434.00 1435.00 1436.00 1437.00 1438.00 1439.00 1440.00 1441.00 1442.00 1443.00 1444.00 1445.00 1446.00 1447.00 1448.00 1449.00 1450.00 1451.00 1452.00 1453.00 1454.00 1455.00 1456.00 1457.00 1458.00 1459.00 1460.00 1461.00 1462.00 1463.00 1464.00 1465.00 1466.00 1467.00 1468.00 1469.00 1470.00 1471.00 1472.00 1473.00 1474.00 1475.00 1476.00 1477.00 1478.00 1479.00 1480.00 1481.00 1482.00 1483.00 1484.00 1485.00 1486.00 1487.00 1488.00 1489.00 1490.00 1491.00 1492.00 1493.00 1494.00 1495.00 1496.00 1497.00 1498.00 1499.00 1500.00 1501.00 1502.00 1503.00 1504.00 1505.00 1506.00 1507.00 1508.00 1509.00 1510.00 1511.00 1512.00 1513.00 1514.00 1515.00 1516.00 1517.00 1518.00 1519.00 1520.00 1521.00 1522.00 1523.00 1524.00 1525.00 1526.00 1527.00 1528.00 1529.00 1530.00 1531.00 1532.00 1533.00 1534.00 1535.00 1536.00 1537.00 1538.00 1539.00 1540.00 1541.00 1542.00 1543.00 1544.00 1545.00 1546.00 1547.00 1548.00 1549.00 1550.00 1551.00 1552.00 1553.00 1554.00 1555.00 1556.00 1557.00 1558.00 1559.00 1560.00 1561.00 1562.00 1563.00 1564.00 1565.00 1566.00 1567.00 1568.00 1569.00 1570.00 1571.00 1572.00 1573.00 1574.00 1575.00 1576.00 1577.00 1578.00 1579.00 1580.00 1581.00 1582.00 1583.00 1584.00 1585.00 1586.00 1587.00 1588.00 1589.00 1590.00 1591.00 1592.00 1593.00 1594.00 1595.00 1596.00 1597.00 1598.00 1599.00 1600.00 1601.00 1602.00 1603.00 1604.00 1605.00 1606.00 1607.00 1608.00 1609.00 1610.00 1611.00 1612.00 1613.00 1614.00 1615.00 1616.00 1617.00 1618.00 1619.00 1620.00 1621.00 1622.00 1623.00 1624.00 1625.00 1626.00 1627.00 1628.00 1629.00 1630.00 1631.00 1632.00 1633.00 1634.00 1635.00 1636.00 1637.00 1638.00 1639.00 1640.00 1641.00 1642.00 1643.00 1644.00 1645.00 1646.00 1647.00 1648.00 1649.00 1650.00 1651.00 1652.00 1653.00 1654.00 1655.00 1656.00 1657.00 1658.00 1659.00 1660.00 1661.00 1662.00 1663.00 1664.00 1665.00 1666.00 1667.00 1668.00 1669.00 1670.00 1671.00 1672.00 1673.00 1674.00 1675.00 1676.00 1677.00 1678.00 1679.00 1680.00 1681.00 1682.00 1683.00 1684.00 1685.00 1686.00 1687.00 1688.00 1689.00 1690.00 1691.00 1692.00 1693.00 1694.00 1695.00 1696.00 1697.00 1698.00 1699.00 1700.00 1701.00 1702.00 1703.00 1704.00 1705.00 1706.00 1707.00 1708.00 1709.00 1710.00 1711.00 1712.00 1713.00 1714.00 1715.00 1716.00 1717.00 1718.00 1719.00 1720.00 1721.00 1722.00 1723.00 1724.00 1725.00 1726.00 1727.00 1728.00 1729.00 1730.00 1731.00 1732.00 1733.00 1734.00 1735.00 1736.00 1737.00 1738.00 1739.00 1740.00 1741.00 1742.00 1743.00 1744.00 1745.00 1746.00 1747.00 1748.00 1749.00 1750.00 1751.00 1752.00 1753.00 1754.00 1755.00 1756.00 1757.00 1758.00 1759.00 1760.00 1761.00 1762.00 1763.00 1764.00 1765.00 1766.00 1767.00 1768.00 1769.00 1770.00 1771.00 1772.00 1773.00 1774.00 1775.00 1776.00 1777.00 1778.00 1779.00 1780.00 1781.00 1782.00 1783.00 1784.00 1785.00 1786.00 1787.00 1788.00 1789.00 1790.00 1791.00 1792.00 1793.00 1794.00 1795.00 1796.00 1797.00 1798.00 1799.00 1800.00 1801.00 1802.00 1803.00 1804.00 1805.00 1806.00 1807.00 1808.00 1809.00 1810.00 1811.00 1812.00 1813.00 1814.00 1815.00 1816.00 1817.00 1818.00 1819.00 1820.00 1821.00 1822.00 1823.00 1824.00 1825.00 1826.00 1827.00 1828.00 1829.00 1830.00 1831.00 1832.00 1833.00 1834.00 1835.00 1836.00 1837.00 1838.00 1839.00 1840.00 1841.00 1842.00 1843.00 1844.00 1845.00 1846.00 1847.00 1848.00 1849.00 1850.00 1851.00 1852.00 1853.00 1854.00 1855.00 1856.00 1857.00 1858.00 1859.00 1860.00 1861.00 1862.00 1863.00 1864.00 1865.00 1866.00 1867.00 1868.00 1869.00 1870.00 1871.00 1872.00 1873.00 1874.00 1875.00 1876.00 1877.00 1878.00 1879.00 1880.00 1881.00 1882.00 1883.00 1884.00 1885.00 1886.00 1887.00 1888.00 1889.00 1890.00 1891.00 1892.00 1893.00 1894.00 1895.00 1896.00 1897.00 1898.00 1899.00 1900.00 1901.00 1902.00 1903.00 1904.00 1905.00 1906.00 1907.00 1908.00 1909.00 1910.00 1911.00 1912.00 1913.00 1914.00 1915.00 1916.00 1917.00 1918.00 1919.00 1920.00 1921.00 1922.00 1923.00 1924.00 1925.00 1926.00 1927.00 1928.00 1929.00 1930.00 1931.00 1932.00 1933.00 1934.00 1935.00 1936.00 1937.00 1938.00 1939.00 1940.00 1941.00 1942.00 1943.00 1944.00 1945.00 1946.00 1947.00 1948.00 1949.00 1950.00 1951.00 1952.00 1953.00 1954.00 1955.00 1956.00 1957.00 1958.00 1959.00 1960.00 1961.00 1962.00 1963.00 1964.00 1965.00 1966.00 1967.00 1968.00 1969.00 1970.00 1971.00 1972.00 1973.00 1974.00 1975.00 1976.00 1977.00 1978.00 1979.00 1980.00 1981.00 1982.00 1983.00 1984.00 1985.00 1986.00 1987.00 1988.00 1989.00 1990.00 1991.00 1992.00 1993.00 1994.00 1995.00 1996.00 1997.00 1998.00 1999.00 2000.00 2001.00 2002.00 2003.00 2004.00 2005.00 2006.00 2007.00 2008.00 2009.00 2010.00 2011.00 2012.00 2013.00 2014.00 2015.00 2016.00 2017.00 2018.00 2019.00 2020.00 2021.00 2022.00 2023.00 2024.00 2025.00 2026.00 2027.00 2028.00 2029.00 2030.00 2031.00 2032.00 2033.00 2034.00 2035.00 2036.00 2037.00 2038.00 2039.00 2040.00 2041.00 2042.00 2043.00 2044.00 2045.00 2046.00 2047.00 2048.00 \n",
            "+++ n = 2048, CPU Result = 2865411072.00, CPU Dot Product time taken = 0.011000 ms\n",
            "+++ Block Dim = (1024, 1)\n",
            "    Grid Dim = (2, 1)\n",
            "+++ Printing float array of length = 2\n",
            "    358438016.00 2506973184.00 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rAL30fjz8Up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "32b7e031-bcb9-496f-dd21-22ff08b18ac4"
      },
      "source": [
        "!/content/src/dotproduct 21 # 33554432"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+++ Name : Tesla T4\n",
            "    Total global memory : 15812263936 bytes\n",
            "    Total shared memory per block : 49152 bytes\n",
            "    Total shared memory per SM : 65536 bytes\n",
            "    Memory bus width : 256 bits\n",
            "    Memory clock rate : 5001000 kHz\n",
            "    Warp size : 32\n",
            "+++ n = 21\n",
            "    size = 84 bytes\n",
            "    n1 = 6\n",
            "+++ Printing float array of length = 21\n",
            "    1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.00 11.00 12.00 13.00 14.00 15.00 16.00 17.00 18.00 19.00 20.00 21.00 \n",
            "+++ Printing float array of length = 21\n",
            "    1.00 2.00 3.00 4.00 5.00 6.00 7.00 8.00 9.00 10.00 11.00 12.00 13.00 14.00 15.00 16.00 17.00 18.00 19.00 20.00 21.00 \n",
            "+++ n = 21, CPU Result = 3311.00, CPU Dot Product time taken = 0.002000 ms\n",
            "+++ Block Dim = (4, 1)\n",
            "    Grid Dim = (6, 1)\n",
            "+++ Printing float array of length = 6\n",
            "    30.00 174.00 446.00 846.00 1374.00 441.00 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYKHhiOTz_ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}